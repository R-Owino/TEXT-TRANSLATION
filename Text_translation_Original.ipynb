{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text translation-Original",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R-Owino/TEXT-TRANSLATION/blob/main/Text_translation_Original.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Translation Using Neural Networks"
      ],
      "metadata": {
        "id": "lVIogMSUpCEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Defining the Question"
      ],
      "metadata": {
        "id": "3ZF_Do3ln3nh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Link to documentation"
      ],
      "metadata": {
        "id": "TlJadNf25gPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is the [link](https://docs.google.com/document/d/1EupL9XjaCt2Hdb7QllS5jkstYJnHv-o_zMagu8EbwbQ/edit?usp=sharing) to the documentation of the project"
      ],
      "metadata": {
        "id": "cBaCfwlu5kAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### i) Specifying the Question"
      ],
      "metadata": {
        "id": "DAA3MzbyoAS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use neural networks to translate English text to a local Kenyan language(Kalenjin)."
      ],
      "metadata": {
        "id": "QgtAD41NoGS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii) Defining the metrics of success"
      ],
      "metadata": {
        "id": "c5_pT03EoGyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a model that can accurately translate English text to Kalenjin with an accuracy score of at least 85%"
      ],
      "metadata": {
        "id": "zFqK4GE1oOAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iii) Understanding the context"
      ],
      "metadata": {
        "id": "d34eGBTqoOxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several translation websites that mostly translate between international languages such as English to Swahili. In Kenya, there a professional bodies that offer translation and interpretation services. Hiring these services can be quite expensive especially when trying to communicate an important information such as constitution interpretation to a pre-dominantly native speaking community. Having a web application can greatly reduce this burden of having to outsource translation services everytime they are needed. \n"
      ],
      "metadata": {
        "id": "1--RTCl7oWD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iv) Recording the Experimental Design"
      ],
      "metadata": {
        "id": "YnBZZo2goaDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Loading the datasets.\n",
        "\n",
        "2. Cleaning the datasets.\n",
        "\n",
        "3. Preprocessing.\n",
        "\n",
        "4. Creating a TensorFlow model.\n",
        "\n",
        "5. Test Processing.\n",
        "\n",
        "6. Training the model.\n",
        "\n",
        "7. Translating.\n",
        "\n",
        "8. Visualizing the process."
      ],
      "metadata": {
        "id": "u9tk83svoium"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### v) Relevance of the data"
      ],
      "metadata": {
        "id": "KUWkCsvEojSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data used in this project is for performing Text Translation using Neural Networks. The datasets can be found [here](https://drive.google.com/drive/folders/1qJgQvNd99E_U6oitRIToOdXPbjqEHqnG)."
      ],
      "metadata": {
        "id": "CQ6TBbY3tKNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Installations"
      ],
      "metadata": {
        "id": "gfHEgJdgwdVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"tensorflow-text==2.8.*\""
      ],
      "metadata": {
        "id": "DUQSvTzIwcoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Importing the libraries"
      ],
      "metadata": {
        "id": "nV1hwDh9s1ZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7PCjt709-91",
        "outputId": "f7c02d6c-96ee-45fd-c6a1-b77d9c891d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# Import TensorFlow >= 1.10 and enable eager execution\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "print(tf.__version__)#to check the tensorflow version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Loading the datasets"
      ],
      "metadata": {
        "id": "_7oYNhBitA8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the datasets\n",
        "english = pd.read_csv('/content/english.txt', sep='delimiter', engine = 'python', header=None)\n",
        "\n",
        "kale = pd.read_csv('/content/kale.txt', sep='delimiter',  engine = 'python', header=None)\n"
      ],
      "metadata": {
        "id": "C6rq-9h7-LVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Previewing the datasets"
      ],
      "metadata": {
        "id": "OXmwhiAZtO7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print the shape of the various datasets\n",
        "files = [english, kale]\n",
        "dataset_names = ['English','Kalenjin']\n",
        "for file in files:\n",
        "  #for index in range(len(dataset_names)):\n",
        "    rows, columns = file.shape\n",
        "    print(f'The dataset has {rows} rows and {columns} columns')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6LnmJjnt3PE",
        "outputId": "3aabd448-cf65-4d11-a811-c23f96bbf4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 176 rows and 1 columns\n",
            "The dataset has 176 rows and 1 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Pre_processing"
      ],
      "metadata": {
        "id": "ItSP4diOv_-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing steps includes\n",
        "\n",
        "- Converting the unicode file to ascii\n",
        "- Creating a space between a word and the punctuation following it\n",
        "eg: “he is a boy.” => “he is a boy .” Reference\n",
        "- Replacing everything with space except (a-z, A-Z, “.”, “?”, “!”, “,”)\n",
        "- Adding a start and an end token to the sentence so that the model know when to start and stop predicting.\n",
        "- Removing the accents\n",
        "- Cleaning the sentences\n",
        "- Return word pairs in the format: [ENGLISH, KALENJIN]\n",
        "- Creating a word -> index mapping (e.g,. 'Further' -> 5) and vice-versa. (e.g., 5 -> 'Further' ) for each language."
      ],
      "metadata": {
        "id": "wKESEW4qxFGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an index column for Kalenjin file\n",
        "kale['index_col'] = kale.index"
      ],
      "metadata": {
        "id": "9Ns6OegFPV-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an index column for Kalenjin file\n",
        "english['index_col'] = kale.index"
      ],
      "metadata": {
        "id": "-LYMqkFVw8Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the English and Kalenjin file with the Index column\n",
        "df_kale = pd.merge(english, kale, on = 'index_col')"
      ],
      "metadata": {
        "id": "vvDFhp9CObTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the Kalenjin Columns\n",
        "df_kale.head()\n",
        "df_kale.columns = ['feature', 'index', 'target']"
      ],
      "metadata": {
        "id": "LnP8rk38PtsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the Index column in the Kalenjjin file\n",
        "df_kale.columns\n",
        "df_kale = df_kale.drop(columns = ['index'])"
      ],
      "metadata": {
        "id": "UhVBZIzUQow5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the first rows on the Kalenjin file\n",
        "df_kale.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CIEp-CbeQypJ",
        "outputId": "9409f00a-ac48-4356-9028-ffc9ac14f25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             feature  \\\n",
              "0  Blessed are the undefiled in the way, who walk...   \n",
              "1  2 Blessed are they that keep his testimonies, ...   \n",
              "2  3 They also do no iniquity: they walk in his w...   \n",
              "3  4 Thou hast commanded us to keep thy precepts ...   \n",
              "4  5 O that my ways were directed to keep thy sta...   \n",
              "\n",
              "                                              target  \n",
              "0  Boiboen che igesunotgei eng’ oret, Che bendote...  \n",
              "1  Boiboen ichek che ribei baornatosiekyik, Che c...  \n",
              "2  Ee, mayaei ichek che ma bo iman; Bendote ortin...  \n",
              "3  Kiing’at konetisiosieguk, Ile kisub eng’ kagii...  \n",
              "4  Ee, kata mie nda ka kimen ortinwekyuk Si kobii...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3796e1d6-0c20-4a2d-b920-4929a3e63707\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Blessed are the undefiled in the way, who walk...</td>\n",
              "      <td>Boiboen che igesunotgei eng’ oret, Che bendote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2 Blessed are they that keep his testimonies, ...</td>\n",
              "      <td>Boiboen ichek che ribei baornatosiekyik, Che c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3 They also do no iniquity: they walk in his w...</td>\n",
              "      <td>Ee, mayaei ichek che ma bo iman; Bendote ortin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4 Thou hast commanded us to keep thy precepts ...</td>\n",
              "      <td>Kiing’at konetisiosieguk, Ile kisub eng’ kagii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5 O that my ways were directed to keep thy sta...</td>\n",
              "      <td>Ee, kata mie nda ka kimen ortinwekyuk Si kobii...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3796e1d6-0c20-4a2d-b920-4929a3e63707')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3796e1d6-0c20-4a2d-b920-4929a3e63707 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3796e1d6-0c20-4a2d-b920-4929a3e63707');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the numbers at the beginning of the feature column\n",
        "df_kale['feature'] = df_kale['feature'].str.replace('\\d+', '')\n",
        "\n",
        "df_kale.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "pi7fEmJ4RKrg",
        "outputId": "1762c513-620e-48f3-ce3f-061ba83667d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             feature  \\\n",
              "0  Blessed are the undefiled in the way, who walk...   \n",
              "1   Blessed are they that keep his testimonies, a...   \n",
              "2   They also do no iniquity: they walk in his ways.   \n",
              "3   Thou hast commanded us to keep thy precepts d...   \n",
              "4   O that my ways were directed to keep thy stat...   \n",
              "\n",
              "                                              target  \n",
              "0  Boiboen che igesunotgei eng’ oret, Che bendote...  \n",
              "1  Boiboen ichek che ribei baornatosiekyik, Che c...  \n",
              "2  Ee, mayaei ichek che ma bo iman; Bendote ortin...  \n",
              "3  Kiing’at konetisiosieguk, Ile kisub eng’ kagii...  \n",
              "4  Ee, kata mie nda ka kimen ortinwekyuk Si kobii...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b09d139-3871-4c33-99c6-66f27cf4e233\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Blessed are the undefiled in the way, who walk...</td>\n",
              "      <td>Boiboen che igesunotgei eng’ oret, Che bendote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Blessed are they that keep his testimonies, a...</td>\n",
              "      <td>Boiboen ichek che ribei baornatosiekyik, Che c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They also do no iniquity: they walk in his ways.</td>\n",
              "      <td>Ee, mayaei ichek che ma bo iman; Bendote ortin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thou hast commanded us to keep thy precepts d...</td>\n",
              "      <td>Kiing’at konetisiosieguk, Ile kisub eng’ kagii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O that my ways were directed to keep thy stat...</td>\n",
              "      <td>Ee, kata mie nda ka kimen ortinwekyuk Si kobii...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b09d139-3871-4c33-99c6-66f27cf4e233')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b09d139-3871-4c33-99c6-66f27cf4e233 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b09d139-3871-4c33-99c6-66f27cf4e233');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_kale['feature'] = df_kale['feature'].str.replace('\\d+', '')\n",
        "\n",
        "df_kale['target'] = df_kale['target'].str.replace('\\d+', '')\n",
        "\n",
        "df_kale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "JxzDPMwJc3yR",
        "outputId": "0f4fa90f-f43a-48f5-d085-a283299319fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               feature  \\\n",
              "0    Blessed are the undefiled in the way, who walk...   \n",
              "1     Blessed are they that keep his testimonies, a...   \n",
              "2     They also do no iniquity: they walk in his ways.   \n",
              "3     Thou hast commanded us to keep thy precepts d...   \n",
              "4     O that my ways were directed to keep thy stat...   \n",
              "..                                                 ...   \n",
              "171   My tongue shall speak of thy word: for all th...   \n",
              "172   Let thine hand help me; for I have chosen thy...   \n",
              "173   I have longed for thy salvation, O Lord; and ...   \n",
              "174   Let my soul live, and it shall praise thee; a...   \n",
              "175   I have gone astray like a lost sheep; seek th...   \n",
              "\n",
              "                                                target  \n",
              "0    Boiboen che igesunotgei eng’ oret, Che bendote...  \n",
              "1    Boiboen ichek che ribei baornatosiekyik, Che c...  \n",
              "2    Ee, mayaei ichek che ma bo iman; Bendote ortin...  \n",
              "3    Kiing’at konetisiosieguk, Ile kisub eng’ kagii...  \n",
              "4    Ee, kata mie nda ka kimen ortinwekyuk Si kobii...  \n",
              "..                                                 ...  \n",
              "171  Ingotien ng’elyeptanyu agobo ng’olyondeng’ung’...  \n",
              "172  Ingochobok eung’ung’ kotoreta; Amu kialewen ko...  \n",
              "173  Kigoama emosto agobo yetuneng’ung’, ee Jehovah...  \n",
              "174  Ingosob sobondanyu, si kolosun; Ak ingotoreta ...  \n",
              "175  Kiabetote ko u kechiriet ne betot; cheng’ kibo...  \n",
              "\n",
              "[176 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-962441da-d342-4fbe-97a6-eb7cf806838a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Blessed are the undefiled in the way, who walk...</td>\n",
              "      <td>Boiboen che igesunotgei eng’ oret, Che bendote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Blessed are they that keep his testimonies, a...</td>\n",
              "      <td>Boiboen ichek che ribei baornatosiekyik, Che c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They also do no iniquity: they walk in his ways.</td>\n",
              "      <td>Ee, mayaei ichek che ma bo iman; Bendote ortin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thou hast commanded us to keep thy precepts d...</td>\n",
              "      <td>Kiing’at konetisiosieguk, Ile kisub eng’ kagii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O that my ways were directed to keep thy stat...</td>\n",
              "      <td>Ee, kata mie nda ka kimen ortinwekyuk Si kobii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>My tongue shall speak of thy word: for all th...</td>\n",
              "      <td>Ingotien ng’elyeptanyu agobo ng’olyondeng’ung’...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>Let thine hand help me; for I have chosen thy...</td>\n",
              "      <td>Ingochobok eung’ung’ kotoreta; Amu kialewen ko...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>I have longed for thy salvation, O Lord; and ...</td>\n",
              "      <td>Kigoama emosto agobo yetuneng’ung’, ee Jehovah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>Let my soul live, and it shall praise thee; a...</td>\n",
              "      <td>Ingosob sobondanyu, si kolosun; Ak ingotoreta ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>I have gone astray like a lost sheep; seek th...</td>\n",
              "      <td>Kiabetote ko u kechiriet ne betot; cheng’ kibo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-962441da-d342-4fbe-97a6-eb7cf806838a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-962441da-d342-4fbe-97a6-eb7cf806838a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-962441da-d342-4fbe-97a6-eb7cf806838a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = df_kale['target'].to_list()"
      ],
      "metadata": {
        "id": "npB5UQG4epUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targ = df_kale['feature'].to_list()"
      ],
      "metadata": {
        "id": "5oa6ivQBcE4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Creating tf_dataset"
      ],
      "metadata": {
        "id": "tPz-5B-ve5OG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a tf.data.Dataset of strings that shuffles and batches them efficiently:"
      ],
      "metadata": {
        "id": "skpuhugPjU6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tells TensorFlow to create a buffer of at most buffer_size elements, and a background thread to fill that buffer in the background\n",
        "BUFFER_SIZE = len(inp)\n",
        "\n",
        "# Number of samples to be feed into the neural network\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Creating the dataset and shuffling it \n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "dataset "
      ],
      "metadata": {
        "id": "Yn3o0fzUez0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9e9f77-93b6-4f97-e84c-d939146db1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX98Wa1bHlsE",
        "outputId": "e0fb979a-a84a-48d5-d1a7-6f848a6db9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'Yachi kiboitiondeng\\xe2\\x80\\x99ung\\xe2\\x80\\x99 ko u rireneng\\xe2\\x80\\x99ung\\xe2\\x80\\x99, Ak ineta ng\\xe2\\x80\\x99atutiguk.'\n",
            " b'Si malilan, Ye aribe komie ng\\xe2\\x80\\x99atutiguk tugul.'\n",
            " b'A kiboitiondeng\\xe2\\x80\\x99ung\\xe2\\x80\\x99, kona naet; Si anai baornatosieguk.'\n",
            " b'Amu kaige sotet ne kiginde iyeto; Ago mautie ng\\xe2\\x80\\x99atutiguk.'\n",
            " b'Ingotien ng\\xe2\\x80\\x99elyeptanyu agobo ng\\xe2\\x80\\x99olyondeng\\xe2\\x80\\x99ung\\xe2\\x80\\x99; Amu bo iman ng\\xe2\\x80\\x99atutiguk.'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b' Deal with thy servant according unto thy mercy, and teach me thy statutes.'\n",
            " b' Then shall I not be ashamed, when I have respect unto all thy commandments.'\n",
            " b' I am thy servant; give me understanding, that I may know thy testimonies.'\n",
            " b' For I am become like a bottle in the smoke; yet do I not forget thy statutes.'\n",
            " b' My tongue shall speak of thy word: for all thy commandments are righteousness.'], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Text processing"
      ],
      "metadata": {
        "id": "_kCgCCkofZql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### i) Standardization"
      ],
      "metadata": {
        "id": "QxJjvOzYfeSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the model is dealing with multilingual text with a limited vocabulary standardization of the text is crucial. Steps;\n",
        "1.  Unicode normalization to split accented characters\n",
        "2.  replace compatibility characters with their ASCII equivalents."
      ],
      "metadata": {
        "id": "zbsccb0GlpPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_text as tf_text"
      ],
      "metadata": {
        "id": "qimZmadJge4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of a text normalized and uni encoded\n",
        "sample_text = tf.constant('Kiacheng’in eng’ muguleldanyu tugul')\n",
        "\n",
        "print(sample_text.numpy())\n",
        "print(tf_text.normalize_utf8(sample_text, 'NFKD').numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaXEDlsSfcDu",
        "outputId": "0c822a3e-c4b1-4a25-f290-da0be7b7b08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Kiacheng\\xe2\\x80\\x99in eng\\xe2\\x80\\x99 muguleldanyu tugul'\n",
            "b'Kiacheng\\xe2\\x80\\x99in eng\\xe2\\x80\\x99 muguleldanyu tugul'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unicode normalization \n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ],
      "metadata": {
        "id": "hvbI7A7hgaBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Priniting an example of the original text\n",
        "print(sample_text.numpy().decode())\n",
        "\n",
        "# printing the text afterunicode normalization\n",
        "print(tf_lower_and_split_punct(sample_text).numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTC9ec0vg2w9",
        "outputId": "83f16ba8-a298-4b63-e257-21857336067b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kiacheng’in eng’ muguleldanyu tugul\n",
            "[START] kiachengin eng muguleldanyu tugul [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting and coverting input text to sequences of tokens\n",
        "# max_vocab_size limit RAM usage during the initial scan of the training corpus to discover the vocabulary.\n",
        "max_vocab_size = 25000 \n",
        "\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)"
      ],
      "metadata": {
        "id": "pcG-ObPshAmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading one epoch of the training data with the adapt method \n",
        "input_text_processor.adapt(inp)\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euDjRG9ZhEPH",
        "outputId": "050498dc-11db-43de-af1a-a326621b3837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', ',', 'ak', 'eng', 'amu', 'ngatutiguk']"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the Kalenjin TextVectorization layer to build the English layer with .adapt() method\n",
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdrMYNIzhKO1",
        "outputId": "bcced218-3f52-42bc-e1f1-b7938475c4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'thy', '[START]', '[END]', '.', 'i', ',', 'me', 'and']"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the layers created to convert a batch of strings into a batch of token IDs\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens[:3, :10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGz0sQG2hRI9",
        "outputId": "daabf2eb-dfd5-4492-f545-8c89909c985f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10), dtype=int64, numpy=\n",
              "array([[  2, 115,  27,  13,  17, 123,   5,   6,  30,   9],\n",
              "       [  2,  14, 131,   5,  37,  79, 283,   9,  20,   4],\n",
              "       [  2,  54,  27,   5,  44,  39,  14, 479,  22,   4]])>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the token IDs that are zero-padded that can be turned into a mask\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens)\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "AMFb-oOlhSBZ",
        "outputId": "fbed47ce-304f-4580-b0d6-90c05e189b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining constants for the model\n",
        "# Embedding layer enables us to convert each word into a fixed length vector of defined size\n",
        "embedding_dim = 512\n",
        "units = 1024"
      ],
      "metadata": {
        "id": "W34FhUHQhXYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  The encoder"
      ],
      "metadata": {
        "id": "yfs8q1paheh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing to do is build the encoder. The process is as follows:\n",
        "\n",
        "1. Taking a list of token IDs. \n",
        "\n",
        "2. Using the embedding vector for each token.\n",
        "\n",
        "3. Processessing the embeddings into a new sequence "
      ],
      "metadata": {
        "id": "MfGvULMIxdyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the  list of token IDs\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ],
      "metadata": {
        "id": "JF5tj3-LhaoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the input text to tokens.\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCGAOYOKhhyU",
        "outputId": "193d4b52-d0d6-4a1a-f79d-db9d980e5dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch, shape (batch): (16,)\n",
            "Input batch tokens, shape (batch, s): (16, 22)\n",
            "Encoder output, shape (batch, s, units): (16, 22, 1024)\n",
            "Encoder state, shape (batch, units): (16, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  The attention head"
      ],
      "metadata": {
        "id": "VS6yGwmvh7wE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decoder uses attention to selectively focus on parts of the input sequence. The attention takes a sequence of vectors as input for each example and returns an \"attention\" vector for each example. "
      ],
      "metadata": {
        "id": "pyENzTlKzQJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shapechecker"
      ],
      "metadata": {
        "id": "kY6rStF8huvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to prevent loading of data of wrong shape"
      ],
      "metadata": {
        "id": "tTMhMqrChhVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "metadata": {
        "id": "RCF51Lophw-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The BahdanauAttention class handles the weight matrices in a pair of dense layers and calls the builtin implementation\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "CNl8GtARh-_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention head layer"
      ],
      "metadata": {
        "id": "s8lEay96iFaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a BahdanauAttention layer\n",
        "attention_layer = BahdanauAttention(units)"
      ],
      "metadata": {
        "id": "p3D4q8LqiDDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excluding the padding\n",
        "(example_tokens != 0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXZOMPBeiLJT",
        "outputId": "5ae2f4c7-8a9a-4832-8309-e35b92219bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Later, the decoder will generate this attention query\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0))\n",
        "\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAIY77zQiOLi",
        "outputId": "45e54065-0df5-44fd-909d-f5d0d74210d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (16, 2, 1024)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (16, 2, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# attention weights across the sequences at t=0\n",
        "# t is used for slicing, for selecting different parts of the data.\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "S3sxTlpbiSbN",
        "outputId": "46ec1700-3508-4b00-dbbc-87c59f9d3d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYcElEQVR4nO3deZRcZZnH8e+vk05CANkJISxBxCgqQehRcGMXRI7gjM6A6ATFaR2XccFBHXVk3MdxRB2d4USJQVRQARU9HsMiEBQEA7IHDGqEhIQQIBLEkO70M3/cG6h0163uvnVreZPf55w+qbrvXZ6qPP3UW7fqPq2IwMzM0tPT6QDMzKwcF3Azs0S5gJuZJcoF3MwsUS7gZmaJcgE3M0uUC3iLSTpH0sc6HUc9kl4u6Z4xrnu4pGWtjskMQNLVkt7a6Ti63WZZwPP//EclTR62fKmko2vuz5QUkiZWdNzTJP2ydllEvD0iPlnF/qsWEddGxKwq9iVpvqRPVbEvS0P++7Re0s7Dlv82/72a2ZnIthybXQHPk+blQACv6WgwZpu/PwKnbLwj6QXA1M6Fs2XZ7Ao48I/Ar4H5wJyNCyWdD+wF/ETS45LOBBbmw2vyZYfm675F0uJ8Fr9A0t41+wlJb5e0RNIaSV9T5rnAOcCh+b7W5OtvMjOV9E+S7pX0iKRLJe0+2r6HP0BJUyT9dePMR9JHJA1KekZ+/5OSvpTfnizpC5Luk/Rgfkpnq3xsk9Mikg7KZ09rJf1A0veGz6olnSFplaQVkt6cL+sHTgXOzB/7T/LlH5S0PN/fPZKOGs9/pCXhfLLfuY3mAN/aeEfSq/OcekzS/ZLOqhmbIunbkh7O8/03kqYNP4Ck6ZJuk/SvrXwgSYqIzeoHuBd4B3AwMABMqxlbChxdc38m2Ux9Ys2yE/N9PBeYCHwUuK5mPICfAtuTvSA8BByXj50G/HJYPPOBT+W3jwRWAwcBk4H/ARaOZd91HudC4O/y25cBvwdeVTP22vz22cClwI7AtsBPgM/mY4cDy/Lbk4A/Ae8BeoG/BdbXxH44MAh8Ih8/HngC2GH448zvzwLuB3avea737XR++KfS37WlwNHAPfnvywRgGbB3nssz87x5Adlk8QDgQeCkfPu35fk4Nd/2YOAZ+djVwFuBfYDfAf2dfrzd+LNZzcAlvYwseb4fETeRFbU3jHM3bycrcIsjYhD4DHBg7Swc+FxErImI+4CrgAPHuO9TgXkRcXNEPAl8mGzGPrPEvq8BDsvP3x8AfCW/PwX4G2BhPnvvB94XEY9ExNr88ZxcZ3+HkL1gfSUiBiLiEuDGYesMAJ/Ix38GPE5WqOvZQPYitb+k3ohYGhG/L3piLGkbZ+HHAIuB5RsHIuLqiLg9IoYi4jbgAuCwfHgA2Al4VkRsiIibIuKxmv3uT/Y78PGImNuOB5KazaqAk719uywiVuf3v0vNaZQx2hv4cv6Wbg3wCCBgRs06K2tuPwFsM8Z97042ywUgIh4HHi6572vIZjcHAbcDl5P9YhwC3BsRDwO7kM1ubqp5PD/Pl9eLbXnk05/c/cPWeTh/URs1voi4F3gvcBawStKFtaeLbLNyPtlE6TRqTp8ASHqxpKskPSTpz2QTpJ1rtlsAXCjpAUmfl9Rbs/mpZC8GF7X6AaRqsyng+Xndvyebha6UtBJ4HzBb0ux8teGtF+u1YrwfeFtEbF/zs1VEXDeGMEZr7fgA2QvExpi3JpuBLC/coth1ZLPf1wLXRMRdZKddjicr7pCdrvkr8Lyax7JdRNQruiuAGcPOue85jnhGPPaI+G5EbHxXFMB/jmN/loiI+BPZh5nHA5cMG/4u2Sm8PSNiO7LPiZRvNxAR/xER+wMvAU5g0/PpZ5Hl8HclTWjpg0jUZlPAgZPI3rbvT3ba4UCy83LX8nRSPAg8s2abh4ChYcvOAT4s6XkAkraT9PoxxvAgsIekSQXjFwBvlnSgsq84fga4ISKWjnH/T4mIJ4CbgHfydMG+jmyGc02+zhDwdeBsSbvmj2eGpGPr7PJ6sufvXZImSjoReNE4QtrkuZU0S9KR+eNcR/ZCMjSO/VlaTgeOjIi/DFu+LfBIRKyT9CJqTmlKOkLSC/Li/BjZKZXaHBkAXg9sDXxL0uZUryqxOT0hc4BvRsR9EbFy4w/wVeDU/FzxZ4GP5qcTPpAXwU8Dv8qXHRIRPySbKV4o6THgDuBVY4zhF8CdwEpJq4cPRsQVwMeAi8lmvPtS/3z0WF1D9oHijTX3t+Xpb9cAfJDsQ9lf54/nCuqct46I9WQfXJ4OrAHeSPaB6pNjjOVcsvPdayT9iOz89+fIZlArgV3JzvnbZigifh8Ri+oMvQP4hKS1wL8D368Z243s9MhjZOfOryE7rVK73415OQ2Y5yK+KW16ytPsaZJuAM6JiG92OhYzG8mvZvYUSYdJ2i0/hTKH7NstP+90XGZW36gFXNK8/MKNO4Ytf7ekuyXdKenzrQvR2mgWcCvZKZQzgNdFxIrOhtQ6zm1L3ainUCS9guz7vt+KiOfny44APgK8OiKelLRrRKxqebRmFXJuW+pGnYFHxEKy70LX+meyC06ezNdxgltynNuWurJd+J4NvFzSp8m+IvaBiPhNvRXzPhn9AD1Teg+euteO4zqQRv1qdX3BiBYiY9uuweFGdiVpXtWfIfcsWV/tDhOylkdXR0S9i5TGo1Rubz1VBz/nWUXfHrUq/O62LbdHVlFuly3gE8l6axxCdtn29yU9M+qcj8kvgZ0LsO2s3eKF//umETvraVCkJ/SU++rwhqHiNxdDDYr7UBSPTVRxLI322Uij45Wx1Sv/WOn+UnJFXPSn0dcaVanc7ps9JW5csFcFh7cix+4+e/SVNlNFuV32WyjLgEsicyPZl+93HmUbsxQ4ty0ZZQv4j4AjACQ9m6yT3YgLV8wS5Ny2ZIx6CkXSBWRNk3ZW1jv648A8squi7iBrOTqn3ltMs27m3LbUjVrAI+KUgqE3VhyLWVs5ty11vhLTzCxRLuBmZolyATczS5QLuJlZolzAzcwS5QJuZpYoF3Azs0S5gJuZJapsM6tSnjFxHUdPu2fE8kaNoBo1uprSM1AqjnVDvYVjvT2DhWMDQ8VPV9lmVo0e37UHTC61T7NutiU3paqaZ+BmZolyATczS5QLuJlZolzAzcwS5QJuZpYoF3Azs0S5gJuZJcoF3MwsUS7gZmaJGrWAS5onaVX+NwKHj50hKST5r3ZbcpzblrqxzMDnA8cNXyhpT+CVwH0Vx2TWLvNxblvCRi3gEbEQeKTO0NnAmdCgmYdZF3NuW+pKnQOXdCKwPCJurTges45ybltKxt2NUNJU4N/I3mKOZf1+oB9gu+lbjbtrX6P1126YMq59bdSrDYVjjToONupUuG3PusKxJ4aKuwoOxITCMWuvZnJ7rxltbexpBpSbge8L7APcKmkpsAdws6Td6q0cEXMjoi8i+qbuMKl8pGatVzq3d9nJL8TWfuOeNkTE7cCuG+/nid4XEasrjMus7ZzblpqxfI3wAuB6YJakZZJOb31YZq3n3LbUjToDj4hTRhmfWVk0Zm3k3LbU+UpMM7NEuYCbmSXKBdzMLFEu4GZmiXIBNzNLlAu4mVmiXMDNzBLlAm5mligXcDOzRLW1hdrawSlcs+pZle1v/YZy4U/oGSq3nYq3iyjumjjeDoxPubz+4p4Gbap7j/lTuWOZtcmCB8p16j1299kVR5I+z8DNzBLlAm5mligXcDOzRLmAm5klygXczCxRLuBmZolyATczS5QLuJlZolzAzcwSNZY/ajxP0ipJd9Qs+y9Jd0u6TdIPJW3f2jDNqufcttSNZQY+Hzhu2LLLgedHxAHA74APVxyXWTvMx7ltCRu1gEfEQuCRYcsui4jB/O6vgT1aEJtZSzm3LXVVNLN6C/C9okFJ/UA/wHbTt+KwXe8dsU6j5kyNGkFtiOLXn0aNp3q1odTYQEwotd26od7CsUaP71cHTCocs7YYc27vNaOtfeGS5qZU1WnqQ0xJHwEGge8UrRMRcyOiLyL6pu7ggmRpGG9u77JT8Yu7WauUnjZIOg04ATgqIoqn0GaJcW5bKkoVcEnHAWcCh0XEE9WGZNY5zm1LyVi+RngBcD0wS9IySacDXwW2BS6XdIukc1ocp1nlnNuWulFn4BFxSp3F57YgFrO2cm5b6nwlpplZolzAzcwS5QJuZpYoF3Azs0S5gJuZJcoF3MwsUS7gZmaJcgE3M0tUW1uorR2cwtUP7jeubSb0FHcVHBgqbiA0FMVd/np7ijsHRoPtGnUOLNtRsVGcPZePvw3H5GOWjnsbs3Za8MCtpbZzF8ORPAM3M0uUC7iZWaJcwM3MEuUCbmaWKBdwM7NEuYCbmSXKBdzMLFEu4GZmiXIBNzNL1Fj+JuY8Sask3VGzbEdJl0takv+7Q2vDNKuec9tSN5YZ+HzguGHLPgRcGRH7AVfm981SMx/ntiVs1AIeEQuBR4YtPhE4L799HnBSxXGZtZxz21JXtpnVtIhYkd9eCUwrWlFSP9APMHW3bZi+9WMj1pnUoLnUYBS/xjRqBNVIo+P1qLh51mCD5lmN4qza6pc82rZjbYFK5fZeM9raF26z5YZV49N01YmIgOJWfBExNyL6IqJv8vZTmj2cWduMJ7d32an4xd2sVcoW8AclTQfI/11VXUhmHeXctmSULeCXAnPy23OAH1cTjlnHObctGWP5GuEFwPXALEnLJJ0OfA44RtIS4Oj8vllSnNuWulE/eYmIUwqGjqo4FrO2cm5b6nwlpplZolzAzcwS5QJuZpYoF3Azs0S5gJuZJcoF3MwsUS7gZmaJcgE3M0tUW1uo7TNpLefP/MWI5RuiuANgI70qDn+I4n32NHjdGojBBvss7GtED8WdEU+YcXDhmFmq3Dmw8zwDNzNLlAu4mVmiXMDNzBLlAm5mligXcDOzRLmAm5klygXczCxRLuBmZolyATczS1RTBVzS+yTdKekOSRdImlJVYGad5Ny2FJQu4JJmAP8C9EXE84EJwMlVBWbWKc5tS0Wzp1AmAltJmghMBR5oPiSzruDctq5XuoBHxHLgC8B9wArgzxFx2fD1JPVLWiRp0eqHN5SP1KxNyuT2Q85t6wBFFHfYa7ihtANwMfAPwBrgB8BFEfHtom22mr5n7PPm99fZWYMDlQuv4T7VoPlhNIqlFdp9vCIln2c12C7KTg9KxrL4s++/KSL6Sh71KWVyu2/2lLhxwV7NHtqsrgnTl9TN7WZOoRwN/DEiHoqIAeAS4CVN7M+sWzi3LQnNFPD7gEMkTZUk4ChgcTVhmXWUc9uS0Mw58BuAi4Cbgdvzfc2tKC6zjnFuWyqa+os8EfFx4OMVxWLWNZzblgJfiWlmligXcDOzRLmAm5klygXczCxRLuBmZolyATczS5QLuJlZolzAzcwS1dSFPOO1445rOfkNV41Y3tszWGp/Qw26JfWquDvcuqHe4n026C7V06DLUqPtGmm0z2sPmFxqn1sqX+uehmN3n93pEBK0pO5Sz8DNzBLlAm5mligXcDOzRLmAm5klygXczCxRLuBmZolyATczS5QLuJlZolzAzcwS1VQBl7S9pIsk3S1psaRDqwrMrJOc25aCZi+l/zLw84h4naRJwNQKYjLrBs5t63qlC7ik7YBXAKcBRMR6YH01YZl1jnPbUtHMKZR9gIeAb0r6raRvSNp6+EqS+iUtkrToL4/6d8CSMO7cfujh4uZpZq3SzCmUicBBwLsj4gZJXwY+BHysdqWImAvMBdjpubvEPX+ZNmJHjTryNTLYoBvhRA0VjvWo+HiN9lnWUJTrVLjzdfWXr37Jo01EY2Mw7tzumz2lXBJvgRY8cGvhmDsVjk8z1WoZsCwibsjvX0SW9Gapc25bEkoX8IhYCdwvaVa+6CjgrkqiMusg57alotlvobwb+E7+Kf0fgDc3H5JZV3BuW9drqoBHxC1AX0WxmHUN57alwFdimpklygXczCxRLuBmZolyATczS5QLuJlZolzAzcwS5QJuZpYoF3Azs0Q1eyXmuEzpGWD/bVaMa5t1Q72ljtWr4u5wExo0uprcM1A4NhATiseGqn8qrz1gcuX7NOs0N6yqjmfgZmaJcgE3M0uUC7iZWaJcwM3MEuUCbmaWKBdwM7NEuYCbmSXKBdzMLFEu4GZmiWq6gEuaIOm3kn5aRUBm3cK5bd2uihn4e4DFFezHrNs4t62rNVXAJe0BvBr4RjXhmHUH57aloNkZ+JeAM4HC7lCS+iUtkrToL4+ub/JwZm0zrtx+6OHi5mlmrVK6hZ6kE4BVEXGTpMOL1ouIucBcgJ2eu0vc/fhuI9bpURQeZzCKX2MmNugquH6ouHNgWY2ON4SKx6J4rJFdr6//vKw6dE2p/dnYlMntvtlTipPYNrHggVsLx9ypcHyamYG/FHiNpKXAhcCRkr5dSVRmneXctiSULuAR8eGI2CMiZgInA7+IiDdWFplZhzi3LRX+HriZWaIq+TMyEXE1cHUV+zLrJs5t62aegZuZJcoF3MwsUS7gZmaJcgE3M0uUC7iZWaJcwM3MEuUCbmaWKBdwM7NEuYCbmSWqkisxx2pKzwDP2WbliOWTewYKt3liw+TCsUYdAHsobg43EOU6FfaquGVob89g4dhQg46KjVz9gq1KbWfWzdxxsDqegZuZJcoF3MwsUS7gZmaJcgE3M0uUC7iZWaJcwM3MEuUCbmaWKBdwM7NElS7gkvaUdJWkuyTdKek9VQZm1inObUtFM1diDgJnRMTNkrYFbpJ0eUTcVVFsZp3i3LYklJ6BR8SKiLg5v70WWAzMqCows05xblsqKjkHLmkm8ELghir2Z9YtnNvWzZpuZiVpG+Bi4L0R8Vid8X6gH2C76fWbMzVqWNWoSdTAUHH4EzRUONYKjRpWbSjZzMo6azy5vdeMtvaFMwOanIFL6iVL8O9ExCX11omIuRHRFxF9W+8wqZnDmbXNeHN7l53Kdbg0a0Yz30IRcC6wOCK+WF1IZp3l3LZUNDMDfynwJuBISbfkP8dXFJdZJzm3LQmlT9xFxC+hwV9UMEuUc9tS4U/XzMwS5QJuZpYoF3Azs0S5gJuZJcoF3MwsUS7gZmaJcgE3M0uUC7iZWaJcwM3MEtXWFmrrhnq5+/HdRizvURRus36o+iZBjY43FMUX4E0s2eFwqORFfbteX3/5qkPXlNqfWTdY8MCthWPH7j67jZGkzzNwM7NEuYCbmSXKBdzMLFEu4GZmiXIBNzNLlAu4mVmiXMDNzBLlAm5mligXcDOzRDVVwCUdJ+keSfdK+lBVQZl1mnPbUlC6gEuaAHwNeBWwP3CKpP2rCsysU5zblopmZuAvAu6NiD9ExHrgQuDEasIy6yjntiWhmWZWM4D7a+4vA148fCVJ/UB/fvfJbx9y7h1NHLNKOwOrOx0E3RMHdE8sZePYu6Ljl8rtCdOXdENud8v/IZSKZUmXxNEyleZ2y7sRRsRcYC6ApEUR0dfqY45Ft8TSLXFA98TSLXGMphtzu1vigO6JpVvigOpjaeYUynJgz5r7e+TLzFLn3LYkNFPAfwPsJ2kfSZOAk4FLqwnLrKOc25aE0qdQImJQ0ruABcAEYF5E3DnKZnPLHq8FuiWWbokDuieWjsaReG53SxzQPbF0SxxQcSyKKP7rNGZm1r18JaaZWaJcwM3MEtWWAt5NlyVLWirpdkm3SFrU5mPPk7RK0h01y3aUdLmkJfm/O3QojrMkLc+fl1skHd/qOPLj7inpKkl3SbpT0nvy5W1/Xspwbj91bOf2pnG0Ja9bXsC79LLkIyLiwA58N3Q+cNywZR8CroyI/YAr8/udiAPg7Px5OTAiftaGOAAGgTMiYn/gEOCdeX504nkZF+f2Jubj3K7VlrxuxwzclyXnImIh8MiwxScC5+W3zwNO6lAcHRERKyLi5vz2WmAx2ZWQbX9eSnBu55zbI+JoS163o4DXuyx5RhuOWySAyyTdlF8K3WnTImJFfnslMK2DsbxL0m3529C2n7KQNBN4IXAD3fW8FHFuN9ZN/4cdy+1W5vWW+CHmyyLiILK3ve+U9IpOB7RRZN/p7NT3Ov8P2Bc4EFgB/Hc7Dy5pG+Bi4L0R8VjtWIefl5Q4t+vrWG63Oq/bUcC76rLkiFie/7sK+CHZ2+BOelDSdID831WdCCIiHoyIDRExBHydNj4vknrJkvw7EXFJvrgrnpdROLcb64r/w07ldjvyuh0FvGsuS5a0taRtN94GXgl0uoPcpcCc/PYc4MedCGJjUuVeS5ueF0kCzgUWR8QXa4a64nkZhXO7sa74P+xEbrctryOi5T/A8cDvgN8DH2nHMQvieCZwa/5zZ7tjAS4gews3QHa+9HRgJ7JPo5cAVwA7diiO84HbgdvyJJvepufkZWRvI28Dbsl/ju/E81Iyfud2cU5tsbndrrz2pfRmZonaEj/ENDPbLLiAm5klygXczCxRLuBmZolyATczS5QLuJlZolzAzcwS9f9cvWxUdQXCSgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the shape of the attention weights\n",
        "attention_weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtKEg3H-iWHO",
        "outputId": "a6adfad9-6e4f-4f6b-b3cf-3535816e75f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 2, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_slice = attention_weights[0, 0].numpy()\n",
        "attention_slice = attention_slice[attention_slice != 0]"
      ],
      "metadata": {
        "id": "nLIfNuypiZs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Toogle code"
      ],
      "metadata": {
        "id": "5-EMQsamifCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting attention weights\n",
        "plt.suptitle('Attention weights for one sequence')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "a1 = plt.subplot(1, 2, 1)\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\n",
        "# freeze the xlim\n",
        "plt.xlim(plt.xlim())\n",
        "plt.xlabel('Attention weights')\n",
        "\n",
        "a2 = plt.subplot(1, 2, 2)\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\n",
        "plt.xlabel('Attention weights, zoomed')\n",
        "\n",
        "# zoom in\n",
        "top = max(a1.get_ylim())\n",
        "zoom = 0.85*top\n",
        "a2.set_ylim([0.90*top, top])\n",
        "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kC-M1cWiihZl",
        "outputId": "f82d6968-4489-4635-bf07-f100a0f6ae5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f058a68b450>]"
            ]
          },
          "metadata": {},
          "execution_count": 125
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The decoder"
      ],
      "metadata": {
        "id": "8aJ1-TaViluf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decoder generates predictions for the next output token.\n",
        "1. The decoder receives the complete encoder output.\n",
        "\n",
        "2. It uses an RNN to keep track of what it has generated so far.\n",
        "\n",
        "3. It uses its RNN output as the query to the attention over the encoder's output, producing the context vector.\n",
        "\n",
        "4. It combines the RNN output and the context vector to generate the attention vector.\n",
        "\n",
        "5. It generates logit predictions for the next token based on the attention vector."
      ],
      "metadata": {
        "id": "QRld9r7zaAao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder class and its initializer creates all the necessary layers.\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # The embedding layer convets token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    #  Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ],
      "metadata": {
        "id": "y2w6cOE_ijbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import typing\n",
        "from typing import Any, Tuple"
      ],
      "metadata": {
        "id": "4BJX5xOzi2Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the call method for this layer which  takes and returns multiple tensors.\n",
        "# Organizing those into simple container classes.\n",
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ],
      "metadata": {
        "id": "f7aMUkaXisc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the call method\n",
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "  if state is not None:\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Lookup the embeddings\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "  # Process one step with the RNN\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  #  Use the RNN output as the query for the attention over the\n",
        "  # encoder output.\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "  #  Join the context_vector and rnn_output\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "  #  `at = tanh(Wc@[ct; ht])`\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "  # Generate logit predictions:\n",
        "  logits = self.fc(attention_vector)\n",
        "  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ],
      "metadata": {
        "id": "hb46LHidjFpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Decoder.call = call"
      ],
      "metadata": {
        "id": "zyzKL0jmjnK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing  of the decoder \n",
        "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)"
      ],
      "metadata": {
        "id": "PAUFYYjFjJoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the target sequence, and collect the \"[START]\" tokens\n",
        "example_output_tokens = output_text_processor(example_target_batch)\n",
        "\n",
        "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
        "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
      ],
      "metadata": {
        "id": "QOCS-aMZjMex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the decoder\n",
        "dec_result, dec_state = decoder(\n",
        "    inputs = DecoderInput(new_tokens=first_token,\n",
        "                          enc_output=example_enc_output,\n",
        "                          mask=(example_tokens != 0)),\n",
        "    state = example_enc_state\n",
        ")\n",
        "\n",
        "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n",
        "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8tAW2qgjPX-",
        "outputId": "b7bb18de-872f-4cdb-f990-960ee5e9a808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape: (batch_size, t, output_vocab_size) (16, 1, 486)\n",
            "state shape: (batch_size, dec_units) (16, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling a token with the logits\n",
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)"
      ],
      "metadata": {
        "id": "r0Sr9yCejyGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoding the token as the first word of the output\n",
        "vocab = np.array(output_text_processor.get_vocabulary())\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_36L8TSj3RB",
        "outputId": "38e625f0-7f15-4872-d5f3-44057dc0bff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['zeal'],\n",
              "       ['sound'],\n",
              "       ['forsake'],\n",
              "       ['thou'],\n",
              "       ['perfection']], dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the same enc_output, mask and sampled tokens as new tokens.\n",
        "\n",
        "dec_result, dec_state = decoder(\n",
        "    DecoderInput(sampled_token,\n",
        "                 example_enc_output,\n",
        "                 mask=(example_tokens != 0)),\n",
        "    state=dec_state)"
      ],
      "metadata": {
        "id": "5-K4tG9kkEDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a second set of logits using the decoder\n",
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OSaBZEQkLex",
        "outputId": "2481d028-17e4-4df8-dcf1-06047a0cde1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['ancients'],\n",
              "       ['offend'],\n",
              "       ['know'],\n",
              "       ['perfection'],\n",
              "       ['are']], dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Training"
      ],
      "metadata": {
        "id": "-ng_jdDekShC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train the model we'll follow the following steps:\n",
        "\n",
        "1. A loss function and optimizer to perform the optimization.\n",
        "\n",
        "2. A training step function defining how to update the model for each input/target batch.\n",
        "\n",
        "3. A training loop to drive the training and save checkpoints."
      ],
      "metadata": {
        "id": "L_FDJCl_gkoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### i) Define the loss function"
      ],
      "metadata": {
        "id": "SCjXzI_1k8Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the loss function and optimizer to perform the optimization.\n",
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ],
      "metadata": {
        "id": "C2IcOwyKj8At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii) Implementing the training step"
      ],
      "metadata": {
        "id": "CaII-2g3lLmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing a model class, the training process will be implemented as the train_step method \n",
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ],
      "metadata": {
        "id": "TTsZs60qkcOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting a batch of input_text, target_text from the tf.data.Dataset.\n",
        "def _preprocess(self, input_text, target_text):\n",
        "  self.shape_checker(input_text, ('batch',))\n",
        "  self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask"
      ],
      "metadata": {
        "id": "yR_m1uF4kfzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTranslator._preprocess = _preprocess"
      ],
      "metadata": {
        "id": "s-oqNm4zlZZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the _train_step method\n",
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs  \n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  # Apply an optimization step\n",
        "  variables = self.trainable_variables \n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Return a dict mapping metric names to current value\n",
        "  return {'batch_loss': average_loss}"
      ],
      "metadata": {
        "id": "fyD9YlGlkhiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTranslator._train_step = _train_step"
      ],
      "metadata": {
        "id": "j3mVALlPmbLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ],
      "metadata": {
        "id": "dOehrED0md0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTranslator._loop_step = _loop_step"
      ],
      "metadata": {
        "id": "nNBAPnZwmfFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iii) Test the training step"
      ],
      "metadata": {
        "id": "__19iWQPmiwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a TrainTranslator and configuring it for training using the Model.compile method\n",
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "metadata": {
        "id": "kf7vv-CqmnDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the train_step model\n",
        "np.log(output_text_processor.vocabulary_size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7YpBQGgmpeq",
        "outputId": "af01d8b3-b753-4f63-aed4-2d5f56e26c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.186208623900494"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the tf.function-wrapped _tf_train_step, to maximize performance while training\n",
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ],
      "metadata": {
        "id": "65UeaPVZmsKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTranslator._tf_train_step = _tf_train_step"
      ],
      "metadata": {
        "id": "1pHTE-FLmw4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator.use_tf_function = True"
      ],
      "metadata": {
        "id": "IrDSsPrsmzC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tracing the function\n",
        "translator.train_step([example_input_batch, example_target_batch])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_uZLIwbnChM",
        "outputId": "6113e6a6-dfde-456d-e400-14aeae8cf9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.816311>}"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing out the Batch loss of our model\n",
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNHqOaK0nDRa",
        "outputId": "a3b0ec56-4ba2-4056-a9f6-9131b64b511c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.725759>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.5690393>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.150142>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.5359273>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.350606>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.2049136>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.020926>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8031235>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.6317313>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.5176616>}\n",
            "\n",
            "CPU times: user 51.6 s, sys: 1.18 s, total: 52.8 s\n",
            "Wall time: 27.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting our batch losses\n",
        "losses = []\n",
        "for n in range(100):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([example_input_batch, example_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KOl01ZMFnOsT",
        "outputId": "060d3a4d-4434-4fe1-9ebb-90385b26bc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "....................................................................................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f058cc127d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building another model to train\n",
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "metadata": {
        "id": "LPHSFGQwnSCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iv) Train the model"
      ],
      "metadata": {
        "id": "pY3YQsfan-O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a couple of epochs by applying the callbacks.Callback method\n",
        "# to collect the history of batch losses\n",
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ],
      "metadata": {
        "id": "TNhN4bJHoBSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the batch loss using 37 epochs \n",
        "train_translator.fit(dataset, epochs=37,\n",
        "                     callbacks=[batch_loss])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgA08TIfoEvf",
        "outputId": "d416efbe-5f1e-4857-da1d-1f5aeb58cdbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/37\n",
            "11/11 [==============================] - 33s 2s/step - batch_loss: 5.5283\n",
            "Epoch 2/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 4.5290\n",
            "Epoch 3/37\n",
            "11/11 [==============================] - 27s 2s/step - batch_loss: 4.0334\n",
            "Epoch 4/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 3.6632\n",
            "Epoch 5/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 3.3573\n",
            "Epoch 6/37\n",
            "11/11 [==============================] - 27s 2s/step - batch_loss: 3.0332\n",
            "Epoch 7/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 2.7042\n",
            "Epoch 8/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 2.4004\n",
            "Epoch 9/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 2.0915\n",
            "Epoch 10/37\n",
            "11/11 [==============================] - 27s 2s/step - batch_loss: 1.8329\n",
            "Epoch 11/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 1.6006\n",
            "Epoch 12/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 1.3591\n",
            "Epoch 13/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 1.1002\n",
            "Epoch 14/37\n",
            "11/11 [==============================] - 27s 2s/step - batch_loss: 0.8800\n",
            "Epoch 15/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.7108\n",
            "Epoch 16/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.5524\n",
            "Epoch 17/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.4271\n",
            "Epoch 18/37\n",
            "11/11 [==============================] - 27s 2s/step - batch_loss: 0.3226\n",
            "Epoch 19/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.2370\n",
            "Epoch 20/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.1722\n",
            "Epoch 21/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.1361\n",
            "Epoch 22/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0995\n",
            "Epoch 23/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0756\n",
            "Epoch 24/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0544\n",
            "Epoch 25/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0427\n",
            "Epoch 26/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0319\n",
            "Epoch 27/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0248\n",
            "Epoch 28/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0187\n",
            "Epoch 29/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0156\n",
            "Epoch 30/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0139\n",
            "Epoch 31/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0117\n",
            "Epoch 32/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0104\n",
            "Epoch 33/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0093\n",
            "Epoch 34/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0086\n",
            "Epoch 35/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0081\n",
            "Epoch 36/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0074\n",
            "Epoch 37/37\n",
            "11/11 [==============================] - 26s 2s/step - batch_loss: 0.0069\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f058cbe6e10>"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the epochs\n",
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ],
      "metadata": {
        "id": "cPsGUSJkqWi6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "ca6071a1-03f6-4fef-8ba6-0f8530b96e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CE/token')"
            ]
          },
          "metadata": {},
          "execution_count": 157
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Translate"
      ],
      "metadata": {
        "id": "079uq-8ZqcCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Executing the full text => texttranslation\n",
        "# This is by inverting the text => token IDsmapping provided by the output_text_processor\n",
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    # The output should never generate padding, unknown, or start.\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))"
      ],
      "metadata": {
        "id": "pee0S4sxqbZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ],
      "metadata": {
        "id": "Q1zOGt-eqjgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63cd1f20-4918-4f4c-805a-d898115876b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### i) Convert IDs to text"
      ],
      "metadata": {
        "id": "pDZbxQB3qp3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the tokens_to_text which converts from token IDs to human readable text.\n",
        "def tokens_to_text(self, result_tokens):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "  shape_checker(result_text, ('batch'))\n",
        "\n",
        "  result_text = tf.strings.strip(result_text)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "  return result_text"
      ],
      "metadata": {
        "id": "KphbGFO7q9Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Translator.tokens_to_text = tokens_to_text"
      ],
      "metadata": {
        "id": "NCmFMywfqsO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inputting some random token IDs and see what it generates (example)\n",
        "example_output_tokens = tf.random.uniform(\n",
        "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
        "    maxval=output_text_processor.vocabulary_size())\n",
        "translator.tokens_to_text(example_output_tokens).numpy()"
      ],
      "metadata": {
        "id": "Po_ThN89rEWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171180c3-5469-4e9c-9b98-eb5a3c505ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'from nothing', b'doest beseech', b'perished right',\n",
              "       b'shalt whole', b'heritage unless'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ii) Sample from the decoder's predictions"
      ],
      "metadata": {
        "id": "4muFfacgrL9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking the decoder's logit outputs and samples token IDs from the distribution\n",
        "def sample(self, logits, temperature):\n",
        "  shape_checker = ShapeChecker()\n",
        "  # 't' is usually 1 here.\n",
        "  shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "  shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  if temperature == 0.0:\n",
        "    new_tokens = tf.argmax(logits, axis=-1)\n",
        "  else: \n",
        "    logits = tf.squeeze(logits, axis=1)\n",
        "    new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "\n",
        "  shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "  return new_tokens"
      ],
      "metadata": {
        "id": "aYIHYKfJrKOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Translator.sample = sample"
      ],
      "metadata": {
        "id": "VteBiIP0rS8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random inputs (example)\n",
        "example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n",
        "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
        "example_output_tokens"
      ],
      "metadata": {
        "id": "jNDKC8OyrZ2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20680f96-3b8e-4983-e27a-2f1e630d3c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
              "array([[302],\n",
              "       [ 17],\n",
              "       [ 60],\n",
              "       [ 14],\n",
              "       [ 39]])>"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iii) Implement translation loop"
      ],
      "metadata": {
        "id": "j5Nr3PkorXYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking the results into python lists before joining them  using tf.concat into tensors.\n",
        "# This unfolds the graph out to max_length iterations.\n",
        "def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "\n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    attention.append(dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    result_tokens.append(new_tokens)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generates token ids to a list of strings.\n",
        "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}"
      ],
      "metadata": {
        "id": "spIWGzjNrVsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Translator.translate = translate_unrolled"
      ],
      "metadata": {
        "id": "uSzYfqdFripi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running a simple input to view the translation\n",
        "%%time\n",
        "input_text = tf.constant([\n",
        "    'kiamwaite eng kutinnyu kiruogutik tugul che bunu kutingung', # \"with my lips have i declared all the judgments of thy mouth\n",
        "    'a kiprutoiyo eng ngony ameungena ngatutiguk', # \"i am a stranger in the earth hide not thy commandments from me\"\n",
        "])\n",
        "\n",
        "\n",
        "result = translator.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ],
      "metadata": {
        "id": "Gncwm1c6rlmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbc7363-6183-48ac-b27f-f327a9496365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with my lips have i declared all the judgments of thy mouth .\n",
            "i am a stranger in the earth hide not thy commandments from me .\n",
            "\n",
            "CPU times: user 803 ms, sys: 9.92 ms, total: 813 ms\n",
            "Wall time: 673 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model"
      ],
      "metadata": {
        "id": "A2mW0SjSs5Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "k4zv5GXft2HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SavedModel format is what we will use to save our model"
      ],
      "metadata": {
        "id": "Y3sVpT2Rs81S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.saved_model.save(translator, 'translator')"
      ],
      "metadata": {
        "id": "sr5wzjeitGNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89dd199d-b072-4d19-ae21-45d42200b35c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as encoder_5_layer_call_fn, encoder_5_layer_call_and_return_conditional_losses, decoder_5_layer_call_fn, decoder_5_layer_call_and_return_conditional_losses, embedding_10_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: translator/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: translator/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded = tf.saved_model.load('translator')\n",
        "result = translator.translate(input_text)"
      ],
      "metadata": {
        "id": "9N4_UY5HyYE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "result = translator.translate(input_text)\n",
        "\n",
        "for tr in result['text']:\n",
        "  print(tr.numpy().decode())\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHjos88GyeUo",
        "outputId": "7d7ffcc3-a69e-4e14-c12b-45fbbeb68780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with my lips have i declared all the judgments of thy judgments .\n",
            "i am a stranger in the earth hide not thy commandments from me .\n",
            "\n",
            "CPU times: user 776 ms, sys: 13 ms, total: 789 ms\n",
            "Wall time: 642 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Conclusion"
      ],
      "metadata": {
        "id": "0tcB73funwpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a). Did we have the right data? The dataset is insufficient, to accurately train the model. A larger dataset with more characters needs in order to improve prediction accuracy.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rj2G7roFn1hN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b). Do we need other data to answer our question? Yes"
      ],
      "metadata": {
        "id": "MjuvLmo6bF01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) Did we have the right question? Yes"
      ],
      "metadata": {
        "id": "rS0AjWVvbaPM"
      }
    }
  ]
}