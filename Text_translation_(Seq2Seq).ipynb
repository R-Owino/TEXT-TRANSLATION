{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R-Owino/TEXT-TRANSLATION/blob/main/Text_translation_(Seq2Seq).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVIogMSUpCEz"
      },
      "source": [
        "# Text Translation Using Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZF_Do3ln3nh"
      },
      "source": [
        "##  Defining the Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlJadNf25gPO"
      },
      "source": [
        "### Link to documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBaCfwlu5kAO"
      },
      "source": [
        "The following is the [link](https://docs.google.com/document/d/1EupL9XjaCt2Hdb7QllS5jkstYJnHv-o_zMagu8EbwbQ/edit?usp=sharing) to the documentation of the project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAA3MzbyoAS5"
      },
      "source": [
        "### i) Specifying the Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgtAD41NoGS5"
      },
      "source": [
        "Use neural networks to translate English text to a local Kenyan language(Kalenjin)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5_pT03EoGyj"
      },
      "source": [
        "### ii) Defining the metrics of success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFqK4GE1oOAi"
      },
      "source": [
        "Building a model that can accurately translate English text to Kalenjin with an accuracy score of at least 85%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d34eGBTqoOxR"
      },
      "source": [
        "### iii) Understanding the context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1--RTCl7oWD6"
      },
      "source": [
        "There are several translation websites that mostly translate between international languages such as English to Swahili. In Kenya, there a professional bodies that offer translation and interpretation services. Hiring these services can be quite expensive especially when trying to communicate an important information such as constitution interpretation to a pre-dominantly native speaking community. Having a web application can greatly reduce this burden of having to outsource translation services everytime they are needed. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnBZZo2goaDa"
      },
      "source": [
        "### iv) Recording the Experimental Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9tk83svoium"
      },
      "source": [
        "1. Loading the datasets.\n",
        "\n",
        "2. Cleaning the datasets.\n",
        "\n",
        "3. Preprocessing.\n",
        "\n",
        "4. Creating a TensorFlow model.\n",
        "\n",
        "5. Test Processing.\n",
        "\n",
        "6. Training the model.\n",
        "\n",
        "7. Translating.\n",
        "\n",
        "8. Visualizing the process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUWkCsvEojSL"
      },
      "source": [
        "### v) Relevance of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ6TBbY3tKNC"
      },
      "source": [
        "The data used in this project is for performing Text Translation using Neural Networks. The datasets can be found [here](https://drive.google.com/drive/folders/1qJgQvNd99E_U6oitRIToOdXPbjqEHqnG)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfHEgJdgwdVU"
      },
      "source": [
        "##  Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUQSvTzIwcoe"
      },
      "outputs": [],
      "source": [
        "# !pip install \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV1hwDh9s1ZP"
      },
      "source": [
        "##  Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7PCjt709-91",
        "outputId": "988b73cf-6c45-4c7d-c7a4-c40de4197098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# Import TensorFlow >= 1.10 and enable eager execution\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "print(tf.__version__)#to check the tensorflow version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7oYNhBitA8V"
      },
      "source": [
        "##  Loading the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C6rq-9h7-LVk"
      },
      "outputs": [],
      "source": [
        "# Loading the datasets\n",
        "english = pd.read_csv('/content/english.txt', sep='delimiter', engine = 'python', header=None)\n",
        "\n",
        "kale = pd.read_csv('/content/kale.txt', sep='delimiter',  engine = 'python', header=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXmwhiAZtO7C"
      },
      "source": [
        "##  Previewing the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6LnmJjnt3PE",
        "outputId": "446e473a-4aff-4d57-9434-7b8369a6f7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset has 176 rows and 1 columns\n",
            "The dataset has 176 rows and 1 columns\n"
          ]
        }
      ],
      "source": [
        "# print the shape of the various datasets\n",
        "files = [english, kale]\n",
        "dataset_names = ['English','Kalenjin']\n",
        "for file in files:\n",
        "  #for index in range(len(dataset_names)):\n",
        "    rows, columns = file.shape\n",
        "    print(f'The dataset has {rows} rows and {columns} columns')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItSP4diOv_-v"
      },
      "source": [
        "##  Pre_processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKESEW4qxFGo"
      },
      "source": [
        "Preprocessing steps includes\n",
        "\n",
        "- Converting the unicode file to ascii\n",
        "- Creating a space between a word and the punctuation following it\n",
        "eg: “he is a boy.” => “he is a boy .” Reference\n",
        "- Replacing everything with space except (a-z, A-Z, “.”, “?”, “!”, “,”)\n",
        "- Adding a start and an end token to the sentence so that the model know when to start and stop predicting.\n",
        "- Removing the accents\n",
        "- Cleaning the sentences\n",
        "- Return word pairs in the format: [ENGLISH, KALENJIN]\n",
        "- Creating a word -> index mapping (e.g,. 'Further' -> 5) and vice-versa. (e.g., 5 -> 'Further' ) for each language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9Ns6OegFPV-j"
      },
      "outputs": [],
      "source": [
        "# Creating an index column for Kalenjin file\n",
        "kale['index_col'] = kale.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-LYMqkFVw8Oe"
      },
      "outputs": [],
      "source": [
        "# Creating an index column for Kalenjin file\n",
        "english['index_col'] = kale.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vvDFhp9CObTv"
      },
      "outputs": [],
      "source": [
        "# Joining the English and Kalenjin file with the Index column\n",
        "df_kale = pd.merge(english, kale, on = 'index_col')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LnP8rk38PtsD"
      },
      "outputs": [],
      "source": [
        "# Renaming the Kalenjin Columns\n",
        "df_kale.head()\n",
        "df_kale.columns = ['feature', 'index', 'target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UhVBZIzUQow5"
      },
      "outputs": [],
      "source": [
        "# Dropping the Index column in the Kalenjjin file\n",
        "df_kale.columns\n",
        "df_kale = df_kale.drop(columns = ['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CIEp-CbeQypJ",
        "outputId": "6b982855-c487-4a9a-b1aa-bc9caabdb624"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             feature  \\\n",
              "0  Joyful are people of integrity, who follow the...   \n",
              "1  Joyful are those who obey his laws and search ...   \n",
              "2  They do not compromise with evil, and they wal...   \n",
              "3  You have charged us to keep your commandments ...   \n",
              "4  Oh, that my actions would consistently reflect...   \n",
              "\n",
              "                                              target  \n",
              "0  Boiboen che igesunotgei eng’ oret, Che bendote...  \n",
              "1  Boiboen ichek che ribei baornatosiekyik, Che c...  \n",
              "2  Ee, mayaei ichek che ma bo iman; Bendote ortin...  \n",
              "3  Kiing’at konetisiosieguk, Ile kisub eng’ kagii...  \n",
              "4  Ee, kata mie nda ka kimen ortinwekyuk Si kobii...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78550213-e34d-4c90-b098-a7fa79ff1ddd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Joyful are people of integrity, who follow the...</td>\n",
              "      <td>Boiboen che igesunotgei eng’ oret, Che bendote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Joyful are those who obey his laws and search ...</td>\n",
              "      <td>Boiboen ichek che ribei baornatosiekyik, Che c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They do not compromise with evil, and they wal...</td>\n",
              "      <td>Ee, mayaei ichek che ma bo iman; Bendote ortin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You have charged us to keep your commandments ...</td>\n",
              "      <td>Kiing’at konetisiosieguk, Ile kisub eng’ kagii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, that my actions would consistently reflect...</td>\n",
              "      <td>Ee, kata mie nda ka kimen ortinwekyuk Si kobii...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78550213-e34d-4c90-b098-a7fa79ff1ddd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78550213-e34d-4c90-b098-a7fa79ff1ddd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78550213-e34d-4c90-b098-a7fa79ff1ddd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Displaying the first rows on the Kalenjin file\n",
        "df_kale.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pi7fEmJ4RKrg",
        "outputId": "ab779f57-ba95-4451-91b5-0e8692163621"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             feature  \\\n",
              "0  Joyful are people of integrity, who follow the...   \n",
              "1  Joyful are those who obey his laws and search ...   \n",
              "2  They do not compromise with evil, and they wal...   \n",
              "3  You have charged us to keep your commandments ...   \n",
              "4  Oh, that my actions would consistently reflect...   \n",
              "\n",
              "                                              target  \n",
              "0  Boiboen che igesunotgei eng’ oret, Che bendote...  \n",
              "1  Boiboen ichek che ribei baornatosiekyik, Che c...  \n",
              "2  Ee, mayaei ichek che ma bo iman; Bendote ortin...  \n",
              "3  Kiing’at konetisiosieguk, Ile kisub eng’ kagii...  \n",
              "4  Ee, kata mie nda ka kimen ortinwekyuk Si kobii...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c90cded5-4c59-4132-8311-bebd2c8321ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Joyful are people of integrity, who follow the...</td>\n",
              "      <td>Boiboen che igesunotgei eng’ oret, Che bendote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Joyful are those who obey his laws and search ...</td>\n",
              "      <td>Boiboen ichek che ribei baornatosiekyik, Che c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They do not compromise with evil, and they wal...</td>\n",
              "      <td>Ee, mayaei ichek che ma bo iman; Bendote ortin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You have charged us to keep your commandments ...</td>\n",
              "      <td>Kiing’at konetisiosieguk, Ile kisub eng’ kagii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, that my actions would consistently reflect...</td>\n",
              "      <td>Ee, kata mie nda ka kimen ortinwekyuk Si kobii...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c90cded5-4c59-4132-8311-bebd2c8321ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c90cded5-4c59-4132-8311-bebd2c8321ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c90cded5-4c59-4132-8311-bebd2c8321ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Removing the numbers at the beginning of the feature column\n",
        "df_kale['feature'] = df_kale['feature'].str.replace('\\d+', '', regex=True)\n",
        "\n",
        "df_kale.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JxzDPMwJc3yR",
        "outputId": "eb34e80e-18ac-4e75-9d3b-c7978d2f9734"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               feature  \\\n",
              "0    Joyful are people of integrity, who follow the...   \n",
              "1    Joyful are those who obey his laws and search ...   \n",
              "2    They do not compromise with evil, and they wal...   \n",
              "3    You have charged us to keep your commandments ...   \n",
              "4    Oh, that my actions would consistently reflect...   \n",
              "..                                                 ...   \n",
              "171  Let my tongue sing about your word, for all yo...   \n",
              "172  Give me a helping hand, for I have chosen to f...   \n",
              "173  O LORD, I have longed for your rescue, and you...   \n",
              "174  Let me live so I can praise you, and may your ...   \n",
              "175  I have wandered away like a lost sheep; come a...   \n",
              "\n",
              "                                                target  \n",
              "0    Boiboen che igesunotgei eng’ oret, Che bendote...  \n",
              "1    Boiboen ichek che ribei baornatosiekyik, Che c...  \n",
              "2    Ee, mayaei ichek che ma bo iman; Bendote ortin...  \n",
              "3    Kiing’at konetisiosieguk, Ile kisub eng’ kagii...  \n",
              "4    Ee, kata mie nda ka kimen ortinwekyuk Si kobii...  \n",
              "..                                                 ...  \n",
              "171  Ingotien ng’elyeptanyu agobo ng’olyondeng’ung’...  \n",
              "172  Ingochobok eung’ung’ kotoreta; Amu kialewen ko...  \n",
              "173  Kigoama emosto agobo yetuneng’ung’, ee Jehovah...  \n",
              "174  Ingosob sobondanyu, si kolosun; Ak ingotoreta ...  \n",
              "175  Kiabetote ko u kechiriet ne betot; cheng’ kibo...  \n",
              "\n",
              "[176 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3b681e7-094f-4a7f-982f-eb73dc3efbd6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Joyful are people of integrity, who follow the...</td>\n",
              "      <td>Boiboen che igesunotgei eng’ oret, Che bendote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Joyful are those who obey his laws and search ...</td>\n",
              "      <td>Boiboen ichek che ribei baornatosiekyik, Che c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They do not compromise with evil, and they wal...</td>\n",
              "      <td>Ee, mayaei ichek che ma bo iman; Bendote ortin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>You have charged us to keep your commandments ...</td>\n",
              "      <td>Kiing’at konetisiosieguk, Ile kisub eng’ kagii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, that my actions would consistently reflect...</td>\n",
              "      <td>Ee, kata mie nda ka kimen ortinwekyuk Si kobii...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>Let my tongue sing about your word, for all yo...</td>\n",
              "      <td>Ingotien ng’elyeptanyu agobo ng’olyondeng’ung’...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>Give me a helping hand, for I have chosen to f...</td>\n",
              "      <td>Ingochobok eung’ung’ kotoreta; Amu kialewen ko...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>O LORD, I have longed for your rescue, and you...</td>\n",
              "      <td>Kigoama emosto agobo yetuneng’ung’, ee Jehovah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>Let me live so I can praise you, and may your ...</td>\n",
              "      <td>Ingosob sobondanyu, si kolosun; Ak ingotoreta ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>I have wandered away like a lost sheep; come a...</td>\n",
              "      <td>Kiabetote ko u kechiriet ne betot; cheng’ kibo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3b681e7-094f-4a7f-982f-eb73dc3efbd6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3b681e7-094f-4a7f-982f-eb73dc3efbd6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3b681e7-094f-4a7f-982f-eb73dc3efbd6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df_kale['feature'] = df_kale['feature'].str.replace('\\d+', '', regex=True)\n",
        "\n",
        "df_kale['target'] = df_kale['target'].str.replace('\\d+', '', regex=True)\n",
        "\n",
        "df_kale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "npB5UQG4epUy"
      },
      "outputs": [],
      "source": [
        "inp = df_kale['target'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5oa6ivQBcE4w"
      },
      "outputs": [],
      "source": [
        "targ = df_kale['feature'].to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPz-5B-ve5OG"
      },
      "source": [
        "##  Creating tf_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skpuhugPjU6G"
      },
      "source": [
        "Creating a tf.data.Dataset of strings that shuffles and batches them efficiently:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn3o0fzUez0p",
        "outputId": "85afbd26-af87-4d77-9bbb-f30a9b169192"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Tells TensorFlow to create a buffer of at most buffer_size elements, and a background thread to fill that buffer in the background\n",
        "BUFFER_SIZE = len(inp)\n",
        "\n",
        "# Number of samples to be feed into the neural network\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Creating the dataset and shuffling it \n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX98Wa1bHlsE",
        "outputId": "b3b69fb8-ba88-4a86-a649-44ad5a990641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'Kiageer ole bochitu kagesunatetab ge tugul; Ago baraa ng\\xe2\\x80\\x99atutieng\\xe2\\x80\\x99ung\\xe2\\x80\\x99.'\n",
            " b'Keero, kigoama emo agobo konetisiosieguk: Isooba eng\\xe2\\x80\\x99 imandang\\xe2\\x80\\x99ung\\xe2\\x80\\x99.'\n",
            " b'Kigoek ng\\xe2\\x80\\x99atutiguk tienwogikyuk Eng\\xe2\\x80\\x99 gotab rutoitanyu.'\n",
            " b'Yachi kiboitiondeng\\xe2\\x80\\x99ung\\xe2\\x80\\x99 ko u rireneng\\xe2\\x80\\x99ung\\xe2\\x80\\x99, Ak ineta ng\\xe2\\x80\\x99atutiguk.'\n",
            " b'Kiamwaite eng\\xe2\\x80\\x99 kutinnyu Kiruogutik tugul che bunu kuting\\xe2\\x80\\x99ung\\xe2\\x80\\x99.'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'Even perfection has its limits, but your commands have no limit.'\n",
            " b'I long to obey your commandments! Renew my life with your goodness.'\n",
            " b'Your decrees have been the theme of my songs wherever I have lived.'\n",
            " b'I am your servant; deal with me in unfailing love, and teach me your decrees.'\n",
            " b'I have recited aloud all the regulations you have given us.'], shape=(5,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kCgCCkofZql"
      },
      "source": [
        "##  Text processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxJjvOzYfeSA"
      },
      "source": [
        "### i) Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbsccb0GlpPP"
      },
      "source": [
        "Since the model is dealing with multilingual text with a limited vocabulary standardization of the text is crucial. Steps;\n",
        "1.  Unicode normalization to split accented characters\n",
        "2.  replace compatibility characters with their ASCII equivalents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qimZmadJge4G"
      },
      "outputs": [],
      "source": [
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaXEDlsSfcDu",
        "outputId": "8bf7c43d-aa16-47e9-e55b-5094bd64a3b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Kiacheng\\xe2\\x80\\x99in eng\\xe2\\x80\\x99 muguleldanyu tugul'\n",
            "b'Kiacheng\\xe2\\x80\\x99in eng\\xe2\\x80\\x99 muguleldanyu tugul'\n"
          ]
        }
      ],
      "source": [
        "# example of a text normalized and uni encoded\n",
        "sample_text = tf.constant('Kiacheng’in eng’ muguleldanyu tugul')\n",
        "\n",
        "print(sample_text.numpy())\n",
        "print(tf_text.normalize_utf8(sample_text, 'NFKD').numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hvbI7A7hgaBj"
      },
      "outputs": [],
      "source": [
        "# Unicode normalization \n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTC9ec0vg2w9",
        "outputId": "93c2f311-7361-42c0-d147-6181ef2eeb47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kiacheng’in eng’ muguleldanyu tugul\n",
            "[START] kiachengin eng muguleldanyu tugul [END]\n"
          ]
        }
      ],
      "source": [
        "# Priniting an example of the original text\n",
        "print(sample_text.numpy().decode())\n",
        "\n",
        "# printing the text afterunicode normalization\n",
        "print(tf_lower_and_split_punct(sample_text).numpy().decode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pcG-ObPshAmb"
      },
      "outputs": [],
      "source": [
        "# Extracting and coverting input text to sequences of tokens\n",
        "# max_vocab_size limit RAM usage during the initial scan of the training corpus to discover the vocabulary.\n",
        "max_vocab_size = 25000 \n",
        "\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euDjRG9ZhEPH",
        "outputId": "bd687ef5-7e06-4b11-e149-07fdb1a7c41e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', ',', 'ak', 'eng', 'amu', 'ngatutiguk']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Reading one epoch of the training data with the adapt method \n",
        "input_text_processor.adapt(inp)\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdrMYNIzhKO1",
        "outputId": "218dab13-fca8-41b3-d85a-4e40de35a0b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'your', '.', '[START]', '[END]', 'i', ',', 'me', 'my']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Using the Kalenjin TextVectorization layer to build the English layer with .adapt() method\n",
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGz0sQG2hRI9",
        "outputId": "e7caa89e-81e1-4160-a2de-18fd584e2b3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 10), dtype=int64, numpy=\n",
              "array([[  2, 151,  70, 450, 384,  76,  20,  23, 456,  19],\n",
              "       [  2, 360,   5, 144, 431,  33,  21,  35,   7,  75],\n",
              "       [  2, 334,   9, 200,   7, 425, 214,   4,   3,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Using the layers created to convert a batch of strings into a batch of token IDs\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens[:3, :10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "AMFb-oOlhSBZ",
        "outputId": "cb05f17f-2b75-422a-ebd2-845610bc0c9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWDklEQVR4nO3deZSddX3H8c8nk43sZCGQSQIIhFWDOIAVrWFPxRbrqQpFGgU7rba4FKUoFNAuhypV8cipTSEGBYKIqNjjMSyK1FaWBFkCAUKBhCyQEIhJIOvMt3/cJ57LmDnzu8vce3+T9+ucOZn73O8893sn3/nMM8/c5zeOCAEA8jOo2Q0AAKpDgANApghwAMgUAQ4AmSLAASBTBDgAZIoA70e2Z9le2ew+gNzYvsf2x5rdR6sjwBPZ3lz21m17S9ntc5rc2++Gvfim0V3W20rbt9g+tpk9YuCx/bzt7bYn9tj+G9th+4DmdLbnIMATRcSoXW+SVkj647JtNza7vx5WF32OlvR2SU9K+m/bJze3LQxAz0k6e9cN22+WNKJ57exZCPAa2R5m++u2VxdvX7c9rJfaT9p+wvbU4uOusr3C9ku2v2V7r6JuVnHkfKHttbbX2P5opb1FycqIuEzStZL+tdi/bX+t2PdG24/ZPqqWzwP2WN+V9Bdlt+dI+s6uG7bPKI7IN9p+wfYVZfcNt32D7fW2N9h+0Pbkng9gez/bj9r+XH8+kRwR4LW7RKWj3KMlzZR0nKRLexbZvkzSRyS9OyJWSrpS0ozi4w6W1C7psrIP2VfS2GL7+ZKusb13DX3eJukY2yMlnSbpD4vHHyvpg5LW17Bv7LnukzTG9uG22ySdJemGsvtfUyngx0k6Q9LHbb+vuG+OSvM3TdIESX8taUv5zm0fKOmXkr4ZEV/pzyeSIwK8dudI+lJErI2IdZK+KOncsvtt+6sqheaJEbHOtiV1SvpMRLwSEZsk/YtKw7/LjmK/OyLip5I2Szq0hj5XS7JKX0g7VDq9cpgkR8TSiFhTw76xZ9t1FH6qpKWSVu26IyLuiYjHIqI7Ih6VtEDSu4u7d6gU3AdHRFdELI6IjWX7PULSLyRdHhFzG/FEcjO42Q0MAFMkLS+7vbzYtss4lcL6QxHx22LbJJXOEy4uZbmkUri2lX3c+ojYWXb7dUmjauizXVJI2hARP7f9TUnXSNrf9m2SPtvjiwdI9V1J90o6UGWnTyTJ9vEq/bR5lKShkoZJ+n7Zx02TdLPtcSoduV8SETuK+8+R9IykW/v7CeSKI/DarZa0f9nt6cW2XV6V9F5J37Z9QrHtZZV+VDwyIsYVb2OLXzz2lz+V9FBEvCZJEfGNiHibSkc5MyRxfhFViYjlKv0y8z0qnaord5Ok2yVNi4ixkr6l0sGKip8uvxgRR0h6h0pfJ+Xn069Q6WvlpuL0DHogwGu3QNKlticVL6e6TG88B6iIuEelo4nbbB8XEd2S/lPS12zvI0m2222fXs/Gil9Wttu+XNLHJH2h2H6s7eNtD1HpHOVWSd31fGzscc6XdNKuA4QyoyW9EhFbbR8n6c933WH7RNtvLsJ5o0qnVMrncIekD0gaKek7tsmrHviE1O6fJC2S9KikxyQ9VGx7g4i4U9J5kn5i+xhJf6/Sj4f32d4o6S7Vdo673BTbm1U6b/6gpDdLmhURdxT3j1HpG8irKp3yWS+JXxChahHxfxGxaDd3fULSl2xvUung5pay+/ZV6fTIRpXOnf9SpdMq5fvdLun9kiZLmkeIv5H5gw4AkCe+mwFApvoMcNvzigs+lvTYfoHtJ20/bvvL/dci0D+YbeQu5Qh8vqTZ5RtsnyjpTEkzI+JISVfVvzWg380Xs42M9RngEXGvpFd6bP64pCsjYltRs7YfegP6FbON3FV7Ic8MSe+y/c8qvQTtsxHx4O4KbXeqdCGL2tT2thEa0/feR+6V3Ii3bU+uVVv6S0m3Tkn/1AxfvqXvot9x3yW/K02s7U5/BeC2KenrDA17pSu5Vtt39F1TiK4K9luBTXr15YiYVONuqprtkSP8tsMOHlrjQwO7t/jRbbud7WoDfLCk8SqtAXKspFtsvyl285KW4hLYuZI0xuPj+EGn9r33o9+S3shTLyTXauzo5NInrxifXDvjr5Ym13pwBZ/yIWm1sbnnS2979+zfdCTXHvS9V5NrtXx13zWF7s2bk2ujO/1VUnd137K876o+VTXbHTOHxwMLp9fh4YHf17bfst3OdrWvQlkp6bZitbsHVHrx/cQ+PgbIAbONbFQb4D+SdKIk2Z6h0hoHL9erKaCJmG1ko8+f0W0vkDRL0kSX/jzY5ZLmqXRV1BJJ2yXN2d2PmEArY7aRuz4DPCLO7uWuD9e5F6ChmG3kjisxASBTBDgAZIoAB4BMEeAAkCkCHAAyRYADQKYIcADIFAEOAJmqdjGrfrXzSz1X+Ozd1Yf8JLn2wlPOTa499NPPJdfGjAOTa1fPGpdcO2X+42mPX8Hqfgdcel9ybVfwd44xMJ0+ZWazW6jQst1u5QgcADJFgANApghwAMgUAQ4AmSLAASBTBDgAZIoAB4BMEeAAkCkCHAAy1WeA255ne23xNwJ73neh7bDNX+1Gdpht5C7lCHy+pNk9N9qeJuk0SSvq3BPQKPPFbCNjfQZ4RNwraXeLk3xN0kWS+IvdyBKzjdxVdQ7c9pmSVkXEI3XuB2gqZhs5qXg1QtsjJH1BpR8xU+o7JXVK0nCNSHqMjQumJvfzmRtOSq5dduU+ybUHf/b55Fpt3Jxc+tb/2Cu59sV/35pU1/XO9JXVhi5Znlzb/frrybWxfXt6bXcFB7YNXBGxltme3t6SC3uiFwtXN/f7c71WQ6zmCPwgSQdKesT285KmSnrI9r67K46IuRHREREdQzSs+k6B/lf1bE+a0NbANoGSig8bIuIxSb87lC0GvSMiXq5jX0DDMdvITcrLCBdI+rWkQ22vtH1+/7cF9D9mG7nr8wg8Is7u4/4D6tYN0EDMNnLHlZgAkCkCHAAyRYADQKYIcADIFAEOAJkiwAEgUwQ4AGSKAAeATBHgAJCpllxCbeRZq5NrBy2ckFw744tLk2u7nf69re2g/ZNrX/po+n43fCDtuY29+YHkfe5s0ZUAgUaq12qAzcYROABkigAHgEwR4ACQKQIcADJFgANApghwAMgUAQ4AmSLAASBTBDgAZCrljxrPs73W9pKybV+x/aTtR23/0Pa4/m0TqD9mG7lLOQKfL2l2j213SjoqIt4i6WlJn69zX0AjzBezjYz1GeARca+kV3psuyMidhY375M0tR96A/oVs43c1WMxq/Mkfa+3O213SuqUpOEakbTDo/Zek/zgz20ZlVwbW7Ym16772LHJtVsmJZdq2okrkmvHnvZcUt2gUemfg+7Nm5Nro7uCX5EMzIWvkmd7entLrguHXixc/UhybSsvfFXTLzFtXyJpp6Qbe6uJiLkR0RERHUM0rJaHAxqm0tmeNKGtcc0BhaoPG2x/RNJ7JZ0cERWsUQq0NmYbuagqwG3PlnSRpHdHxOv1bQloHmYbOUl5GeECSb+WdKjtlbbPl/RNSaMl3Wn7Ydvf6uc+gbpjtpG7Po/AI+Ls3Wy+rh96ARqK2UbuuBITADJFgANApghwAMgUAQ4AmSLAASBTBDgAZIoAB4BMEeAAkKmWXEJt78HpVzD/9Iq3Jtce/o11ybX7/vjZ5NqYWMGa/9e8llz65NXHJNVNW5i+XMfIe59Oru3etCm5lpULMVC18sqFHIEDQKYIcADIFAEOAJkiwAEgUwQ4AGSKAAeATBHgAJApAhwAMkWAA0CmUv4m5jzba20vKds23vadtpcV/+7dv20C9cdsI3cpR+DzJc3use1iSXdHxCGS7i5uA7mZL2YbGeszwCPiXkmv9Nh8pqTri/evl/S+OvcF9DtmG7mrdjGryRGxpnj/RUmTeyu03SmpU5KGa0TSzhe/c2x6J9/YmVwa69Yn1246+bDk2jH/+3xyrUakfQ4k6fDLnkmqq2TRKU+ckFyrCvY7gFQ129PbW3JdOAxwNf8SMyJCUq/L4UXE3IjoiIiOIRpW68MBDVPJbE+a0NbAzoCSagP8Jdv7SVLx79r6tQQ0FbONbFQb4LdLmlO8P0fSj+vTDtB0zDaykfIywgWSfi3pUNsrbZ8v6UpJp9peJumU4jaQFWYbuevzNy8RcXYvd51c516AhmK2kTuuxASATBHgAJApAhwAMkWAA0CmCHAAyBQBDgCZIsABIFMEOABkqiWXUNv29vSVAIeuGppcG1u2Jtdu3D/9e9uon/RckbR3T/3bMcm1h13+VFJddHUl73PnmpeSaxXd6bVARk6fMrPZLdQFR+AAkCkCHAAyRYADQKYIcADIFAEOAJkiwAEgUwQ4AGSKAAeATBHgAJCpmgLc9mdsP257ie0FtofXqzGgmZht5KDqALfdLumTkjoi4ihJbZLOqldjQLMw28hFradQBkvay/ZgSSMkra69JaAlMNtoeVUHeESsknSVpBWS1kj6bUTc0bPOdqftRbYX7dC26jsFGqSa2V63Pn1BMaBeHBHVfaC9t6QfSPqQpA2Svi/p1oi4obePGePxcfygU/vcd9vIEel9DBuWXNu9aVP6fvfaK7l246mHJ9eOeWpDcu2KM8Yn1e1/04rkfXatWpNcG90VzEYLrFx4V9y6OCI6at1PNbPdMXN4PLBweq0PjRbUCisX9jbbtZxCOUXScxGxLiJ2SLpN0jtq2B/QKphtZKGWAF8h6e22R9i2pJMlLa1PW0BTMdvIQi3nwO+XdKukhyQ9Vuxrbp36ApqG2UYuavqLPBFxuaTL69QL0DKYbeSAKzEBIFMEOABkigAHgEwR4ACQKQIcADJFgANApghwAMgUAQ4AmarpQp7+8tOn/ye59pRzz0uuffYcJ9eOfmxocu2ItemLPsVTzybXTl/1UlJd92tbkvc5qIJFuipZKKxrQ/oiXbktkoU928LVj9R9n/VaIIsjcADIFAEOAJkiwAEgUwQ4AGSKAAeATBHgAJApAhwAMkWAA0CmCHAAyFRNAW57nO1bbT9pe6ntP6hXY0AzMdvIQa2X0l8t6WcR8We2h0oaUYeegFbAbKPlVR3gtsdK+kNJH5GkiNguaXt92gKah9lGLmo5hXKgpHWSvm37N7avtT2yZ5HtTtuLbC/aoW01PBzQMBXP9rr1XY3vEnu8Wk6hDJZ0jKQLIuJ+21dLuljSP5QXRcRcSXMlaYzHJy1DN3t6R3ITaz+VvmLejM4Hk2s9KH3lwuiq4It38JDk0nXvPzypbsK370/eZ/f2Cg4kN29Orx1YKp7tjpnDK1hiEc1Wr9UAm62WI/CVklZGxK70uFWloQdyx2wjC1UHeES8KOkF24cWm06W9ERdugKaiNlGLmp9FcoFkm4sfkv/rKSP1t4S0BKYbbS8mgI8Ih6WlH7CGsgEs40ccCUmAGSKAAeATBHgAJApAhwAMkWAA0CmCHAAyBQBDgCZIsABIFO1XonZL0bfMy65dsqs9AWq2g6Ylly78qrhybXtc1Yl18bW9BUZ51361aS6v1v2ieR9tv3qkeTa6K7g+3t0p9cCTbZwdfrXQSsvfMUROABkigAHgEwR4ACQKQIcADJFgANApghwAMgUAQ4AmSLAASBTBDgAZKrmALfdZvs3tv+rHg0BrYLZRqurxxH4pyQtrcN+gFbDbKOl1RTgtqdKOkPStfVpB2gNzDZyUOsR+NclXSSp15WMbHfaXmR70Q6lL+QENFlFs71ufVfjOgMKVa9GaPu9ktZGxGLbs3qri4i5kuZK0hiPj5R9r/3ygcl9jNr72eTa7lVrkmvbz03/1Gw67cjk2pE/Sl898XMHvyupbuiElcn77G5rS66V0kNpIK1cWM1sd8wcnjTbyE8rr1xYyxH4CZL+xPbzkm6WdJLtG+rSFdBczDayUHWAR8TnI2JqRBwg6SxJP4+ID9etM6BJmG3kgteBA0Cm6vIXeSLiHkn31GNfQCthttHKOAIHgEwR4ACQKQIcADJFgANApghwAMgUAQ4AmSLAASBTBDgAZIoAB4BM1eVKzHob/unVybXdP9uYXLvioo7k2mlXpq8aeNmXr0uuveDov0yuPeCK+5Pqdq59OXmfrb4SIFCtRq8E2Ao4AgeATBHgAJApAhwAMkWAA0CmCHAAyBQBDgCZIsABIFMEOABkquoAtz3N9i9sP2H7cdufqmdjQLMw28hFLVdi7pR0YUQ8ZHu0pMW274yIJ+rUG9AszDayUPUReESsiYiHivc3SVoqqb1ejQHNwmwjF3U5B277AElvlZS2eAeQCWYbrazmxaxsj5L0A0mfjojfW1nKdqekTkkarhFJ+5w6ckPy46/q6kquHfVCJNde8vSi5NorTzg9ufZNW9J/CvfkfZLquipZzOqYI9NrF6f3Gt3pn9tcFtSqZLant7fkunB7lIWrH2l2Cw1fUKumI3DbQ1Qa8Bsj4rbd1UTE3IjoiIiOIRpWy8MBDVPpbE+a0NbYBgHV9ioUS7pO0tKI+Gr9WgKai9lGLmo5Aj9B0rmSTrL9cPH2njr1BTQTs40sVH3iLiJ+Jcl17AVoCcw2csGVmACQKQIcADJFgANApghwAMgUAQ4AmSLAASBTBDgAZIoAB4BMEeAAkKmWXELt0blvSa6dOPO3ybXf+8evJNd+Z8NxybVd0yYl1w56akVybWzdmlQ3/7l7kvd53lFpK0JKUh5rBgJ7Lo7AASBTBDgAZIoAB4BMEeAAkCkCHAAyRYADQKYIcADIFAEOAJkiwAEgUzUFuO3Ztp+y/Yzti+vVFNBszDZyUHWA226TdI2kP5J0hKSzbR9Rr8aAZmG2kYtajsCPk/RMRDwbEdsl3SzpzPq0BTQVs40s1LKYVbukF8pur5R0fM8i252SOoub2+7qvmVJn3u+9pYa2urdQdMqqb69ktqJkl6urJv6aZ9aSfV1le6+qc+tQvvXaT9VzXbbfsv6nu385PT/X4l+el7L6r/Lkt3Odr+vRhgRcyXNlSTbiyKio78fs9EG6vOSBvZzqxWzna+B8rxqOYWySlL5Me3UYhuQO2YbWaglwB+UdIjtA20PlXSWKjvvALQqZhtZqPoUSkTstP23khZKapM0LyIe7+PD5lb7eC1uoD4vaWA/t91itt+A59XCHBHN7gEAUAWuxASATBHgAJCphgT4QL4s2fbzth+z/bDtRc3up1q259lea3tJ2bbxtu+0vaz4d+9m9tiKmO3WN5Bnu98DfA+5LPnEiDg689eVzpc0u8e2iyXdHRGHSLq7uI0Cs52N+Rqgs92II3AuS85ARNwr6ZUem8+UdH3x/vWS3tfQplofs52BgTzbjQjw3V2W3N6Ax22UkHSH7cXFpdUDyeSIWFO8/6Kkyc1spgUx2/kaELPd75fS7wHeGRGrbO8j6U7bTxbf8QeUiAjbvOZ0z8Jst7hGHIEP6MuSI2JV8e9aST9U6cfqgeIl2/tJUvHv2ib302qY7XwNiNluRIAP2MuSbY+0PXrX+5JOkzSQVqS7XdKc4v05kn7cxF5aEbOdrwEx241YjbCay5JzMVnSD21Lpc/lTRHxs+a2VB3bCyTNkjTR9kpJl0u6UtItts+XtFzSB5vXYethtvMwkGebS+kBIFNciQkAmSLAASBTBDgAZIoAB4BMEeAAkCkCHAAyRYADQKb+HxlikytG5+zPAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Applying the token IDs that are zero-padded that can be turned into a mask\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens)\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "W34FhUHQhXYB"
      },
      "outputs": [],
      "source": [
        "# Defining constants for the model\n",
        "# Embedding layer enables us to convert each word into a fixed length vector of defined size\n",
        "embedding_dim = 512\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfs8q1paheh8"
      },
      "source": [
        "##  The encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY6rStF8huvw"
      },
      "source": [
        "### Shapechecker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTMhMqrChhVV"
      },
      "source": [
        "Function to prevent loading of data of wrong shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RCF51Lophw-D"
      },
      "outputs": [],
      "source": [
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CNl8GtARh-_j"
      },
      "outputs": [],
      "source": [
        "# The BahdanauAttention class handles the weight matrices in a pair of dense layers and calls the builtin implementation\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfGvULMIxdyM"
      },
      "source": [
        "The first thing to do is build the encoder. The process is as follows:\n",
        "\n",
        "1. Taking a list of token IDs. \n",
        "\n",
        "2. Using the embedding vector for each token.\n",
        "\n",
        "3. Processessing the embeddings into a new sequence "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "JF5tj3-LhaoV"
      },
      "outputs": [],
      "source": [
        "# Applying the  list of token IDs\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCGAOYOKhhyU",
        "outputId": "54d1fa2a-65c1-4c67-e313-0d4877cb86d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch, shape (batch): (16,)\n",
            "Input batch tokens, shape (batch, s): (16, 14)\n",
            "Encoder output, shape (batch, s, units): (16, 14, 1024)\n",
            "Encoder state, shape (batch, units): (16, 1024)\n"
          ]
        }
      ],
      "source": [
        "# Convert the input text to tokens.\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS6yGwmvh7wE"
      },
      "source": [
        "##  The attention head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyENzTlKzQJL"
      },
      "source": [
        "The decoder uses attention to selectively focus on parts of the input sequence. The attention takes a sequence of vectors as input for each example and returns an \"attention\" vector for each example. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8lEay96iFaK"
      },
      "source": [
        "### Attention head layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "p3D4q8LqiDDG"
      },
      "outputs": [],
      "source": [
        "# Creating a BahdanauAttention layer\n",
        "attention_layer = BahdanauAttention(units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXZOMPBeiLJT",
        "outputId": "053f59ff-cb42-4511-df8c-f5731a00890d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Excluding the padding\n",
        "(example_tokens != 0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAIY77zQiOLi",
        "outputId": "36d2140e-0bda-4cda-c7a4-8ff31ea417cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (16, 2, 1024)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (16, 2, 14)\n"
          ]
        }
      ],
      "source": [
        "# Later, the decoder will generate this attention query\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0))\n",
        "\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "S3sxTlpbiSbN",
        "outputId": "8d1e1737-5c2a-493a-9d24-3d6e76b0db31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# attention weights across the sequences at t=0\n",
        "# t is used for slicing, for selecting different parts of the data.\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens != 0)\n",
        "plt.title('Mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtKEg3H-iWHO",
        "outputId": "1ba86cd5-85b3-4e02-bc76-f5e1c1cb87fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 2, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Displaying the shape of the attention weights\n",
        "attention_weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nLIfNuypiZs1"
      },
      "outputs": [],
      "source": [
        "attention_slice = attention_weights[0, 0].numpy()\n",
        "attention_slice = attention_slice[attention_slice != 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-EMQsamifCP"
      },
      "source": [
        "### Toogle code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "kC-M1cWiihZl",
        "outputId": "7ac3b5f9-347e-4dfb-e97a-6a387046bf7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca392e5210>]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting attention weights\n",
        "plt.suptitle('Attention weights for one sequence')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "a1 = plt.subplot(1, 2, 1)\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\n",
        "# freeze the xlim\n",
        "plt.xlim(plt.xlim())\n",
        "plt.xlabel('Attention weights')\n",
        "\n",
        "a2 = plt.subplot(1, 2, 2)\n",
        "plt.bar(range(len(attention_slice)), attention_slice)\n",
        "plt.xlabel('Attention weights, zoomed')\n",
        "\n",
        "# zoom in\n",
        "top = max(a1.get_ylim())\n",
        "zoom = 0.85*top\n",
        "a2.set_ylim([0.90*top, top])\n",
        "a1.plot(a1.get_xlim(), [zoom, zoom], color='k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aJ1-TaViluf"
      },
      "source": [
        "### The decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRld9r7zaAao"
      },
      "source": [
        "The decoder generates predictions for the next output token.\n",
        "1. The decoder receives the complete encoder output.\n",
        "\n",
        "2. It uses an RNN to keep track of what it has generated so far.\n",
        "\n",
        "3. It uses its RNN output as the query to the attention over the encoder's output, producing the context vector.\n",
        "\n",
        "4. It combines the RNN output and the context vector to generate the attention vector.\n",
        "\n",
        "5. It generates logit predictions for the next token based on the attention vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "y2w6cOE_ijbo"
      },
      "outputs": [],
      "source": [
        "# Decoder class and its initializer creates all the necessary layers.\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # The embedding layer convets token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    #  Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4BJX5xOzi2Ir"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import typing\n",
        "from typing import Any, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "f7aMUkaXisc8"
      },
      "outputs": [],
      "source": [
        "# Applying the call method for this layer which  takes and returns multiple tensors.\n",
        "# Organizing those into simple container classes.\n",
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "hb46LHidjFpW"
      },
      "outputs": [],
      "source": [
        "# Implementing the call method\n",
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "  if state is not None:\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Lookup the embeddings\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "  # Process one step with the RNN\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  #  Use the RNN output as the query for the attention over the\n",
        "  # encoder output.\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "  #  Join the context_vector and rnn_output\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "  #  `at = tanh(Wc@[ct; ht])`\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "  # Generate logit predictions:\n",
        "  logits = self.fc(attention_vector)\n",
        "  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "zyzKL0jmjnK3"
      },
      "outputs": [],
      "source": [
        "Decoder.call = call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "PAUFYYjFjJoL"
      },
      "outputs": [],
      "source": [
        "# Implementing  of the decoder \n",
        "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "QOCS-aMZjMex"
      },
      "outputs": [],
      "source": [
        "# Convert the target sequence, and collect the \"[START]\" tokens\n",
        "example_output_tokens = output_text_processor(example_target_batch)\n",
        "\n",
        "start_index = output_text_processor.get_vocabulary().index('[START]')\n",
        "first_token = tf.constant([[start_index]] * example_output_tokens.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8tAW2qgjPX-",
        "outputId": "45685bac-54f3-4a5d-8306-61905b2d0d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits shape: (batch_size, t, output_vocab_size) (16, 1, 545)\n",
            "state shape: (batch_size, dec_units) (16, 1024)\n"
          ]
        }
      ],
      "source": [
        "# Run the decoder\n",
        "dec_result, dec_state = decoder(\n",
        "    inputs = DecoderInput(new_tokens=first_token,\n",
        "                          enc_output=example_enc_output,\n",
        "                          mask=(example_tokens != 0)),\n",
        "    state = example_enc_state\n",
        ")\n",
        "\n",
        "print(f'logits shape: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n",
        "print(f'state shape: (batch_size, dec_units) {dec_state.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "r0Sr9yCejyGR"
      },
      "outputs": [],
      "source": [
        "# Sampling a token with the logits\n",
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_36L8TSj3RB",
        "outputId": "d6707e23-99d7-489a-cd25-c443af9e2a92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['wiser'],\n",
              "       ['coming'],\n",
              "       ['chosen'],\n",
              "       ['hangs'],\n",
              "       ['how']], dtype='<U13')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Decoding the token as the first word of the output\n",
        "vocab = np.array(output_text_processor.get_vocabulary())\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "5-K4tG9kkEDX"
      },
      "outputs": [],
      "source": [
        "# Applying the same enc_output, mask and sampled tokens as new tokens.\n",
        "\n",
        "dec_result, dec_state = decoder(\n",
        "    DecoderInput(sampled_token,\n",
        "                 example_enc_output,\n",
        "                 mask=(example_tokens != 0)),\n",
        "    state=dec_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OSaBZEQkLex",
        "outputId": "87f4e148-8ad3-4ca8-c488-bde73b2eaa3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['can'],\n",
              "       ['weep'],\n",
              "       ['disregarded'],\n",
              "       ['limit'],\n",
              "       ['they']], dtype='<U13')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Generating a second set of logits using the decoder\n",
        "sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n",
        "first_word = vocab[sampled_token.numpy()]\n",
        "first_word[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ng_jdDekShC"
      },
      "source": [
        "##  Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_FDJCl_gkoW"
      },
      "source": [
        "To train the model we'll follow the following steps:\n",
        "\n",
        "1. A loss function and optimizer to perform the optimization.\n",
        "\n",
        "2. A training step function defining how to update the model for each input/target batch.\n",
        "\n",
        "3. A training loop to drive the training and save checkpoints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCjXzI_1k8Du"
      },
      "source": [
        "### i) Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "C2IcOwyKj8At"
      },
      "outputs": [],
      "source": [
        "# Implementing the loss function and optimizer to perform the optimization.\n",
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaII-2g3lLmO"
      },
      "source": [
        "### ii) Implementing the training step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "TTsZs60qkcOQ"
      },
      "outputs": [],
      "source": [
        "# Implementing a model class, the training process will be implemented as the train_step method \n",
        "class TrainTranslator(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "yR_m1uF4kfzg"
      },
      "outputs": [],
      "source": [
        "# Getting a batch of input_text, target_text from the tf.data.Dataset.\n",
        "def _preprocess(self, input_text, target_text):\n",
        "  self.shape_checker(input_text, ('batch',))\n",
        "  self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "s-oqNm4zlZZg"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._preprocess = _preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "fyD9YlGlkhiY"
      },
      "outputs": [],
      "source": [
        "# Applying the _train_step method\n",
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs  \n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  # Apply an optimization step\n",
        "  variables = self.trainable_variables \n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Return a dict mapping metric names to current value\n",
        "  return {'batch_loss': average_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "j3mVALlPmbLQ"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._train_step = _train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "dOehrED0md0-"
      },
      "outputs": [],
      "source": [
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "nNBAPnZwmfFf"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._loop_step = _loop_step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__19iWQPmiwa"
      },
      "source": [
        "### iii) Test the training step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "kf7vv-CqmnDy"
      },
      "outputs": [],
      "source": [
        "# Building a TrainTranslator and configuring it for training using the Model.compile method\n",
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7YpBQGgmpeq",
        "outputId": "890e22b8-92fd-4e5d-edd0-f6b9119c3738"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.300785794663244"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Testing the train_step model\n",
        "np.log(output_text_processor.vocabulary_size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "65UeaPVZmsKv"
      },
      "outputs": [],
      "source": [
        "# Applying the tf.function-wrapped _tf_train_step, to maximize performance while training\n",
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "1pHTE-FLmw4s"
      },
      "outputs": [],
      "source": [
        "TrainTranslator._tf_train_step = _tf_train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "IrDSsPrsmzC5"
      },
      "outputs": [],
      "source": [
        "translator.use_tf_function = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_uZLIwbnChM",
        "outputId": "7e60c949-34c1-4f39-b072-cec37225f3e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.912616>}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# Tracing the function\n",
        "translator.train_step([example_input_batch, example_target_batch])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNHqOaK0nDRa",
        "outputId": "584c2720-2b2b-4d4c-ad9d-6ef7727322eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.830212>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.692901>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.3484187>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.387675>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.8120604>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.4171376>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.198662>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.015049>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.0684133>}\n",
            "{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.037114>}\n",
            "\n",
            "CPU times: user 42.6 s, sys: 871 ms, total: 43.5 s\n",
            "Wall time: 22.5 s\n"
          ]
        }
      ],
      "source": [
        "# Printing out the Batch loss of our model\n",
        "%%time\n",
        "for n in range(10):\n",
        "  print(translator.train_step([example_input_batch, example_target_batch]))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KOl01ZMFnOsT",
        "outputId": "459c64ed-af21-49bf-e397-1dbc0c29a7ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "....................................................................................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca363e9c10>]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting our batch losses\n",
        "losses = []\n",
        "for n in range(100):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([example_input_batch, example_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "LPHSFGQwnSCL"
      },
      "outputs": [],
      "source": [
        "# Building another model to train\n",
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY3YQsfan-O_"
      },
      "source": [
        "### iv) Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "TNhN4bJHoBSi"
      },
      "outputs": [],
      "source": [
        "# Training a couple of epochs by applying the callbacks.Callback method\n",
        "# to collect the history of batch losses\n",
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgA08TIfoEvf",
        "outputId": "e114e64d-a357-4ce6-bea2-0e69fff16bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/37\n",
            "11/11 [==============================] - 36s 3s/step - batch_loss: 5.6722\n",
            "Epoch 2/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 4.5677\n",
            "Epoch 3/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 4.1810\n",
            "Epoch 4/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 3.8417\n",
            "Epoch 5/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 3.5145\n",
            "Epoch 6/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 3.1842\n",
            "Epoch 7/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 2.8719\n",
            "Epoch 8/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 2.6040\n",
            "Epoch 9/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 2.3185\n",
            "Epoch 10/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 2.0429\n",
            "Epoch 11/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 1.8078\n",
            "Epoch 12/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 1.5138\n",
            "Epoch 13/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 1.2543\n",
            "Epoch 14/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 1.0400\n",
            "Epoch 15/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 0.8174\n",
            "Epoch 16/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.6255\n",
            "Epoch 17/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.4647\n",
            "Epoch 18/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 0.3522\n",
            "Epoch 19/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 0.2506\n",
            "Epoch 20/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 0.1799\n",
            "Epoch 21/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 0.1263\n",
            "Epoch 22/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.0972\n",
            "Epoch 23/37\n",
            "11/11 [==============================] - 30s 3s/step - batch_loss: 0.0713\n",
            "Epoch 24/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 0.0597\n",
            "Epoch 25/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 0.0433\n",
            "Epoch 26/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.0330\n",
            "Epoch 27/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.0258\n",
            "Epoch 28/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 0.0205\n",
            "Epoch 29/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.0165\n",
            "Epoch 30/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.0134\n",
            "Epoch 31/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.0119\n",
            "Epoch 32/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.0105\n",
            "Epoch 33/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.0096\n",
            "Epoch 34/37\n",
            "11/11 [==============================] - 28s 3s/step - batch_loss: 0.0089\n",
            "Epoch 35/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.0082\n",
            "Epoch 36/37\n",
            "11/11 [==============================] - 30s 3s/step - batch_loss: 0.0076\n",
            "Epoch 37/37\n",
            "11/11 [==============================] - 29s 3s/step - batch_loss: 0.0071\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fca363b2e90>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "# Displaying the batch loss using 37 epochs \n",
        "train_translator.fit(dataset, epochs=37,\n",
        "                     callbacks=[batch_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "cPsGUSJkqWi6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "015f5094-8c89-48a1-bd39-eecece5f3156"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CE/token')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting the epochs\n",
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "079uq-8ZqcCF"
      },
      "source": [
        "##  Translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "pee0S4sxqbZL"
      },
      "outputs": [],
      "source": [
        "# Executing the full text => texttranslation\n",
        "# This is by inverting the text => token IDsmapping provided by the output_text_processor\n",
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    # The output should never generate padding, unknown, or start.\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Q1zOGt-eqjgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d55341fb-64eb-4e24-cb1b-d011139cbbd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDZbxQB3qp3H"
      },
      "source": [
        "### i) Convert IDs to text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "KphbGFO7q9Jc"
      },
      "outputs": [],
      "source": [
        "# Implementing the tokens_to_text which converts from token IDs to human readable text.\n",
        "def tokens_to_text(self, result_tokens):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "  shape_checker(result_text, ('batch'))\n",
        "\n",
        "  result_text = tf.strings.strip(result_text)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "  return result_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "NCmFMywfqsO7"
      },
      "outputs": [],
      "source": [
        "Translator.tokens_to_text = tokens_to_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Po_ThN89rEWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901ed4c5-0ff8-4f89-d59a-5c7430076c05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'. accept', b'lord but', b'an evilminded', b'dust united',\n",
              "       b'fills answer'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "# Inputting some random token IDs and see what it generates (example)\n",
        "example_output_tokens = tf.random.uniform(\n",
        "    shape=[5, 2], minval=0, dtype=tf.int64,\n",
        "    maxval=output_text_processor.vocabulary_size())\n",
        "translator.tokens_to_text(example_output_tokens).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4muFfacgrL9E"
      },
      "source": [
        "### ii) Sample from the decoder's predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "aYIHYKfJrKOz"
      },
      "outputs": [],
      "source": [
        "# Taking the decoder's logit outputs and samples token IDs from the distribution\n",
        "def sample(self, logits, temperature):\n",
        "  shape_checker = ShapeChecker()\n",
        "  # 't' is usually 1 here.\n",
        "  shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "  shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  if temperature == 0.0:\n",
        "    new_tokens = tf.argmax(logits, axis=-1)\n",
        "  else: \n",
        "    logits = tf.squeeze(logits, axis=1)\n",
        "    new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "\n",
        "  shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "  return new_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "VteBiIP0rS8S"
      },
      "outputs": [],
      "source": [
        "Translator.sample = sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "jNDKC8OyrZ2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e9e3dd0-3bf7-4082-e32f-d9cd05cc8dd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
              "array([[161],\n",
              "       [299],\n",
              "       [352],\n",
              "       [285],\n",
              "       [347]])>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "# Random inputs (example)\n",
        "example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n",
        "example_output_tokens = translator.sample(example_logits, temperature=1.0)\n",
        "example_output_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5Nr3PkorXYF"
      },
      "source": [
        "### iii) Implement translation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "spIWGzjNrVsC"
      },
      "outputs": [],
      "source": [
        "# Taking the results into python lists before joining them  using tf.concat into tensors.\n",
        "# This unfolds the graph out to max_length iterations.\n",
        "def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "\n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    attention.append(dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    result_tokens.append(new_tokens)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generates token ids to a list of strings.\n",
        "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "uSzYfqdFripi"
      },
      "outputs": [],
      "source": [
        "Translator.translate = translate_unrolled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Gncwm1c6rlmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fee492-5f1a-469c-818c-9d72ccc6c46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i have recited aloud all the regulations you have given us .\n",
            "i am only a foreigner in the land . dont hide your commands from me !\n",
            "\n",
            "CPU times: user 911 ms, sys: 21.2 ms, total: 932 ms\n",
            "Wall time: 758 ms\n"
          ]
        }
      ],
      "source": [
        "# Running a simple input to view the translation\n",
        "%%time\n",
        "input_text = tf.constant([\n",
        "    'kiamwaite eng kutinnyu kiruogutik tugul che bunu kutingung', # \"with my lips have i declared all the judgments of thy mouth\n",
        "    'a kiprutoiyo eng ngony ameungena ngatutiguk', # \"i am a stranger in the earth hide not thy commandments from me\"\n",
        "])\n",
        "\n",
        "\n",
        "result = translator.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrzMLbawJ9pU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAKa6BuDe5Or"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "t7K_qJA-e77L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03847983-cc74-46d8-f739-8087be61ad2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "import math\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "try:\n",
        "  nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "  nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "e_4WkMSrgHci"
      },
      "outputs": [],
      "source": [
        "ref_a = str('all the judgments of thy mouth').split()\n",
        "hyp = str('i have more understanding than all my teachers for thy testimonies are my meditation').split()\n",
        "ref_b = str('all the judgements of your mouth').split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "jvcLFg5BmUos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7c6007-6f1a-4d2e-c383-7437f03b6a9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'have', 'more', 'understanding', 'than', 'all', 'my', 'teachers', 'for', 'thy', 'testimonies', 'are', 'my', 'meditation']\n",
            "['all', 'the', 'judgments', 'of', 'thy', 'mouth']\n",
            "['all', 'the', 'judgements', 'of', 'your', 'mouth']\n"
          ]
        }
      ],
      "source": [
        "print(hyp)\n",
        "print(ref_a)\n",
        "print(ref_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN0cZUkVlQqp"
      },
      "source": [
        "### Sentence BLEU Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uK10FEyrkph"
      },
      "source": [
        "NLTK provides the sentence_bleu() function for evaluating a candidate sentence against one or more reference sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "dpuL5g2fgLv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d45df6f-c16e-4697-eaf3-aa232fcb3147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6147881529512643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "reference = [['all', 'the', 'judgments', 'of', 'thy', 'mouth'], ['all', 'the', 'judgements', 'of', 'your', 'mouth']]\n",
        "candidate = ['i', 'have', 'more', 'understanding', 'than', 'all', 'my', 'teachers', 'for', 'thy', 'testimonies', 'are', 'my', 'meditation']\n",
        "score = sentence_bleu(reference, candidate)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9lDhuW1KxlM"
      },
      "source": [
        "\n",
        "A score of 0.6145 is obtained. This implies the sentences are relatively comparable. 1 implies the two sentences are completly similar and 0 implies the sentences are completely disimilar. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98F2vG2UlYVQ"
      },
      "source": [
        "### Corpus BLEU Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNA3dO5NrjLw"
      },
      "source": [
        "NLTK also provides a function called corpus_bleu() for calculating the BLEU score for multiple sentences such as a paragraph or a document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "1fGBeOnzgQgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca723b91-1a64-4fa1-ab2d-2642125f6aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6147881529512643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "reference = [[['all', 'the', 'judgments', 'of', 'thy', 'mouth'], ['all', 'the', 'judgements', 'of', 'your', 'mouth']]]\n",
        "candidate = [['i', 'have', 'more', 'understanding', 'than', 'all', 'my', 'teachers', 'for', 'thy', 'testimonies', 'are', 'my', 'meditation']]\n",
        "score = corpus_bleu(reference, candidate)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myPS3RxpLTvR"
      },
      "source": [
        "A corpus BLEU score of 0.6145 is obtained similar to sentence BLEU score. This implies that the translation maintaned its context.A score of 0.6145 indicates that the Quality of the translation is often better than human.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu7_PijHlbCU"
      },
      "source": [
        "### Individual N-Gram Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XLc2423rHYu"
      },
      "source": [
        "An individual N-gram score is the evaluation of just matching grams of a specific order, such as single words (1-gram) or word pairs (2-gram or bigram). The weights are specified as a tuple where each index refers to the gram order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "emAFpzBRoGcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb802288-4b8e-49a9-fe87-583bccd3eaf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14285714285714285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 1-gram individual BLEU\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "reference = [['all', 'the', 'judgments', 'of', 'thy', 'mouth']]\n",
        "candidate = ['i', 'have', 'more', 'understanding', 'than', 'all', 'my', 'teachers', 'for', 'thy', 'testimonies', 'are', 'my', 'meditation']\n",
        "score = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0))\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5M7TMzhMWyy"
      },
      "source": [
        "A very low n-gram score was very poor. The original text had six words but the the translation had fourteen letters. This shows the model isn't fully optimized and is still bunching together alot of similar words and needs to be optimized further. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2mW0SjSs5Ty"
      },
      "source": [
        "## Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "k4zv5GXft2HK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3sVpT2Rs81S"
      },
      "source": [
        "The SavedModel format is what we will use to save our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "sr5wzjeitGNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d6b5cd-e3e1-4af1-fc50-a7d6570a7e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as encoder_2_layer_call_fn, encoder_2_layer_call_and_return_conditional_losses, decoder_2_layer_call_fn, decoder_2_layer_call_and_return_conditional_losses, embedding_4_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: translator/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: translator/assets\n"
          ]
        }
      ],
      "source": [
        "model = tf.saved_model.save(translator, 'translator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "9N4_UY5HyYE7"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load('translator')\n",
        "result = translator.translate(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "QHjos88GyeUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ababa685-3c75-4b8d-e8ed-2c2e072327fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i have recited aloud all the regulations you have given us .\n",
            "i am only a foreigner in the land . dont hide your commands from me !\n",
            "\n",
            "CPU times: user 1.07 s, sys: 22 ms, total: 1.09 s\n",
            "Wall time: 843 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = translator.translate(input_text)\n",
        "\n",
        "for tr in result['text']:\n",
        "  print(tr.numpy().decode())\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tcB73funwpf"
      },
      "source": [
        "##  Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlnaPCPMKcGh"
      },
      "source": [
        "With the dataset and metrics we had the translations maintained their context although were too dismilar in terms of structure to the target sentence. \n",
        "From the model metrics, there is a need for the the model to be optimized further. We shall continue building our dataset and optimizing it further. The trained model will be deployed via streamlite  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj2G7roFn1hN"
      },
      "source": [
        "a). Did we have the right data? The dataset is insufficient, to accurately train the model. A larger dataset with more characters needs in order to improve prediction accuracy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjuvLmo6bF01"
      },
      "source": [
        "b). Do we need other data to answer our question? Yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS0AjWVvbaPM"
      },
      "source": [
        "c) Did we have the right question? Yes"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yfs8q1paheh8",
        "VS6yGwmvh7wE",
        "-ng_jdDekShC",
        "079uq-8ZqcCF",
        "HAKa6BuDe5Or",
        "A2mW0SjSs5Ty"
      ],
      "name": "Text translation (Seq2Seq)",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}